{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15ce3aa",
   "metadata": {},
   "source": [
    "# **PREPROCESAMIENTO DE IMÁGENES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136291cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f52e2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Config] Rutas\n",
    "# Ajusta estas rutas según tu estructura\n",
    "BASE_IMAGES_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\Datos\\IMAGES\")   \n",
    "NOTEBOOKS_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\")      \n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_csv(\"./Data/ADNI_Images.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64003c37",
   "metadata": {},
   "source": [
    "## Rutas a archivos y estandarización de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0a9ea",
   "metadata": {},
   "source": [
    "_____________\n",
    "* 1. Verificar y normalizar rutas a archivos .nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ac2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar rutas a los archivos nii\n",
    "def normalize_path(p):\n",
    "    # convierte rutas relativas con .. y / a una Path absoluta\n",
    "    p = str(p)\n",
    "    # Reemplaza barras si vienen con mayúsculas, espacios extra, etc.\n",
    "    return Path(p.replace(\"/\", os.sep)).resolve()\n",
    "df['ruta_abs'] = df['ruta'].apply(lambda p: normalize_path(p) if pd.notnull(p) else p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e8c71",
   "metadata": {},
   "source": [
    "________\n",
    "* 2. Crear identificadores y nombres de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad459148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos campos clave\n",
    "df['sujeto_id'] = df['sujeto_id'].astype(str)\n",
    "df['VISCODE'] = df['VISCODE'].astype(str)\n",
    "# EXAMDATE -> intentar parsear (si ya es datetime, no cambia)\n",
    "def parse_date(x):\n",
    "    if pd.isnull(x): \n",
    "        return pd.NaT\n",
    "    if isinstance(x, (datetime, pd.Timestamp)):\n",
    "        return pd.to_datetime(x)\n",
    "    # probar distintos formatos comunes\n",
    "    for fmt in (\"%Y-%m-%d\", \"%Y/%m/%d\", \"%d-%m-%Y\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%dT%H:%M:%S\"):\n",
    "        try:\n",
    "            return pd.to_datetime(x, format=fmt)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.to_datetime(x, errors='coerce')\n",
    "\n",
    "df['Fecha'] = df['EXAMDATE'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba859da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_visita = sujetoid_VISCODE\n",
    "df['id_visita'] = df['sujeto_id'] + \"_\" + df['VISCODE']\n",
    "# fname_out (sin subcarpetas): sujetoid_EXAMDATE_VISCODE_archivoSinExt.npy\n",
    "def safe_fname(s):\n",
    "    # quita espacios, reemplaza / : etc\n",
    "    return \"\".join(c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in s)\n",
    "\n",
    "def make_output_fname(row):\n",
    "    subj = row['sujeto_id']\n",
    "    vis = row['VISCODE']\n",
    "    examdate = row['Fecha']\n",
    "    exam_str = examdate.strftime(\"%Y%m%d\") if pd.notnull(examdate) else \"noDate\"\n",
    "    arch = Path(row['archivo']).stem\n",
    "    fname = f\"{subj}_{exam_str}_{vis}_{arch}.npy\"\n",
    "    return safe_fname(fname)\n",
    "\n",
    "df['fname_out'] = df.apply(make_output_fname, axis=1)\n",
    "df['ruta_npy'] = df['fname_out'].apply(lambda s: OUT_DIR / s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7e63d",
   "metadata": {},
   "source": [
    "____________\n",
    "* 3. Construir etiquetas binarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31a0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos mapa VISCODE -> meses\n",
    "viscode_to_month = {'bl':0, 'm06':6, 'm12':12, 'm18':18, 'm24':24, 'm30':30, 'm36':36}\n",
    "df['vis_month'] = df['VISCODE'].map(viscode_to_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfedc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dx_is_dementia(dx):\n",
    "    if pd.isnull(dx):\n",
    "        return np.nan\n",
    "    s = str(dx).lower()\n",
    "    if 'dementia' in s:\n",
    "        return 1\n",
    "    if 'mci' in s:\n",
    "        return 0\n",
    "    return np.nan\n",
    "df['is_dementia'] = df['DX'].apply(dx_is_dementia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8180b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando labels por sujeto: 100%|██████████| 51/51 [00:00<00:00, 206.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels por sujeto (ejemplo):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sujeto_id</th>\n",
       "      <th>label_progresion</th>\n",
       "      <th>conversion_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007_S_0101</td>\n",
       "      <td>1</td>\n",
       "      <td>(m24, 24, 2007-12-12 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007_S_0128</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-08-20 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007_S_0249</td>\n",
       "      <td>1</td>\n",
       "      <td>(m12, 12, 2007-04-03 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>013_S_0240</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-10-31 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>014_S_0169</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>018_S_0057</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-08-21 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>018_S_0080</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>018_S_0087</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>018_S_0142</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>018_S_0155</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sujeto_id  label_progresion                 conversion_info\n",
       "0  007_S_0101                 1  (m24, 24, 2007-12-12 00:00:00)\n",
       "1  007_S_0128                 1  (m18, 18, 2007-08-20 00:00:00)\n",
       "2  007_S_0249                 1  (m12, 12, 2007-04-03 00:00:00)\n",
       "3  013_S_0240                 1  (m18, 18, 2007-10-31 00:00:00)\n",
       "4  014_S_0169                 0                            None\n",
       "5  018_S_0057                 1  (m18, 18, 2007-08-21 00:00:00)\n",
       "6  018_S_0080                 0                            None\n",
       "7  018_S_0087                 0                            None\n",
       "8  018_S_0142                 0                            None\n",
       "9  018_S_0155                 0                            None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construir label por sujeto:\n",
    "# Regla: si sujeto presenta transición de non-dementia -> dementia en algún vis <=36 meses -> label 1.\n",
    "# Implementación simplificada:\n",
    "labels = []\n",
    "subjects = df['sujeto_id'].unique()\n",
    "for subj in tqdm(subjects, desc=\"Calculando labels por sujeto\"):\n",
    "    subdf = df[df['sujeto_id']==subj].copy()\n",
    "    # orden por vis_month (si NaN, orden por Fecha)\n",
    "    if subdf['vis_month'].notna().any():\n",
    "        subdf = subdf.sort_values(by=['vis_month','Fecha'])\n",
    "    else:\n",
    "        subdf = subdf.sort_values(by='')\n",
    "    # buscamos primer visita con is_dementia==1 y su mes\n",
    "    # y primer visita con is_dementia==0 (baseline non-dementia)\n",
    "    baseline_non_d = subdf[subdf['is_dementia']==0]\n",
    "    first_non_d = None\n",
    "    if not baseline_non_d.empty:\n",
    "        # preferir VISCODE 'bl' si existe\n",
    "        if (baseline_non_d['VISCODE'].str.lower()=='bl').any():\n",
    "            first_non_d = baseline_non_d[baseline_non_d['VISCODE'].str.lower()=='bl'].iloc[0]\n",
    "        else:\n",
    "            first_non_d = baseline_non_d.iloc[0]\n",
    "    # buscar conversion\n",
    "    converted = False\n",
    "    conversion_info = None\n",
    "    # consideramos cualquier visita con is_dementia==1 y vis_month <= 36\n",
    "    dem_vis = subdf[subdf['is_dementia']==1]\n",
    "    if not dem_vis.empty:\n",
    "        # si hay baseline non-dementia, la conversión debe ocurrir tras baseline\n",
    "        if first_non_d is not None:\n",
    "            # buscar dem_vis cuya month >= baseline month y <=36\n",
    "            base_month = first_non_d.get('vis_month', 0) if pd.notnull(first_non_d.get('vis_month', np.nan)) else 0\n",
    "            # candidate dem_vis posteriores\n",
    "            for _, r in dem_vis.iterrows():\n",
    "                month = r.get('vis_month', np.nan)\n",
    "                if pd.isna(month):\n",
    "                    # si no hay month, intentar por fecha diff\n",
    "                    if pd.notnull(first_non_d['Fecha']) and pd.notnull(r['Fecha']):\n",
    "                        diff_months = (r['Fecha'].year - first_non_d['Fecha'].year)*12 + (r['Fecha'].month - first_non_d['Fecha'].month)\n",
    "                        month = diff_months\n",
    "                # now check range\n",
    "                if pd.notnull(month) and (month >= base_month) and (month <= 36):\n",
    "                    converted = True\n",
    "                    conversion_info = (r['VISCODE'], month, r['Fecha'])\n",
    "                    break\n",
    "        else:\n",
    "            # No baseline non-dementia conocido: fallback -> if any dem_vis within <=36 -> label may be ambiguous:\n",
    "            # we'll mark converted if there's any dem_vis with vis_month<=36\n",
    "            for _, r in dem_vis.iterrows():\n",
    "                month = r.get('vis_month', np.nan)\n",
    "                if pd.notnull(month) and month <= 36:\n",
    "                    converted = True\n",
    "                    conversion_info = (r['VISCODE'], month, r['Fecha'])\n",
    "                    break\n",
    "    # Save label for all rows of this subject (we attach label at image-row level later)\n",
    "    labels.append({'sujeto_id': subj, 'label_progresion': int(converted), 'conversion_info': conversion_info})\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "print(\"Labels por sujeto (ejemplo):\")\n",
    "display(labels_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7c73cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen labels (por sujeto):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_progresion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count\n",
       "label_progresion       \n",
       "0                    29\n",
       "1                    22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resumen de labels\n",
    "# Merge back al df (por sujeto_id)\n",
    "df = df.merge(labels_df[['sujeto_id','label_progresion']], on='sujeto_id', how='left')\n",
    "\n",
    "print(\"Resumen labels (por sujeto):\")\n",
    "display(labels_df['label_progresion'].value_counts(dropna=False).to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487f0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables y labels \n",
    "columnas_id = ['sujeto_id', 'id_visita', 'Fecha', 'VISCODE', 'vis_month', 'is_dementia', 'label_progresion', 'ruta_npy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766f473",
   "metadata": {},
   "source": [
    "## Valores nulos e imputación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786153b",
   "metadata": {},
   "source": [
    "____________\n",
    "* 1. Exploración de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf68150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de variables nulas \n",
    "cognitivas = [\n",
    "    \"CDRSB\", #\"Suma de cajas del Clinical Dementia Rating (CDR); mide la severidad de la demencia.\",\n",
    "    \"MMSE\", #\"Mini-Mental State Examination; evaluación global del estado cognitivo (máx. 30 puntos).\",\n",
    "    \"ADAS13\", #\"Alzheimer’s Disease Assessment Scale – 13 ítems; mide deterioro cognitivo en Alzheimer.\",\n",
    "    \"FAQ\", #\"Functional Activities Questionnaire; evalúa la capacidad funcional en actividades diarias.\",\n",
    "    \"RAVLT_immediate\", # \"Puntuación inmediata en la prueba verbal de aprendizaje (Rey Auditory Verbal Learning Test).\",\n",
    "    \"RAVLT_learning\", # \"Puntuación de aprendizaje acumulado en RAVLT; mide retención verbal.\",\n",
    "    \"RAVLT_forgetting\", # \"Índice de olvido en RAVLT; diferencia entre aprendizaje y recuerdo tardío.\",\n",
    "    \"DIGITSCOR\", #\"Digit Span Score; mide memoria de trabajo y atención mediante secuencias numéricas.\",\n",
    "    \"TRABSCOR\", # \"Trail Making Test B Score; evalúa función ejecutiva y flexibilidad cognitiva.\",\n",
    "]\n",
    "volumen = [\n",
    "    \"Ventricles\", # \"Volumen de los ventrículos cerebrales; puede indicar atrofia cerebral.\",\n",
    "    \"Hippocampus\", # \"Volumen del hipocampo; clave en memoria y afectado en Alzheimer.\",\n",
    "    \"WholeBrain\", # \"Volumen total del cerebro; útil para evaluar atrofia global.\",\n",
    "    \"Entorhinal\", # \"Volumen de la corteza entorrinal; región afectada tempranamente en Alzheimer.\",\n",
    "    \"Fusiform\", #\"Volumen del giro fusiforme; relacionado con reconocimiento visual.\",\n",
    "    \"MidTemp\", # \"Volumen del lóbulo temporal medio; implicado en memoria y procesamiento auditivo.\",\n",
    "    \"ICV\", #\"Volumen intracraneal total; usado para normalizar medidas volumétricas.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d4132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Valores nulos\n",
      "--------------------------------------------------\n",
      "Variables consideradas (cognitivas): \n",
      "['CDRSB', 'MMSE', 'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR']\n",
      "\n",
      "Resumen de nulos por variable:\n",
      "                  nulos  porcentaje\n",
      "FAQ                  31       11.11\n",
      "TRABSCOR             31       11.11\n",
      "CDRSB                30       10.75\n",
      "RAVLT_forgetting     30       10.75\n",
      "ADAS13               29       10.39\n",
      "RAVLT_immediate      29       10.39\n",
      "RAVLT_learning       29       10.39\n",
      "DIGITSCOR            29       10.39\n",
      "MMSE                 28       10.04\n",
      "\n",
      "Filas con al menos un nulo en cognitivas: 38\n",
      "Proporción total: 13.62%\n",
      "--------------------------------------------------\n",
      "Variables consideradas (volumen): \n",
      "['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
      "\n",
      "Resumen de nulos por variable:\n",
      "             nulos  porcentaje\n",
      "Hippocampus     67       24.01\n",
      "Entorhinal      67       24.01\n",
      "Fusiform        67       24.01\n",
      "MidTemp         67       24.01\n",
      "Ventricles      38       13.62\n",
      "WholeBrain      38       13.62\n",
      "ICV             38       13.62\n",
      "\n",
      "Filas con al menos un nulo en volumen: 67\n",
      "Proporción total: 24.01%\n"
     ]
    }
   ],
   "source": [
    "def resumen_nulos(df, variables, nombre_grupo):\n",
    "    # Asegurar que las variables existan en el DataFrame\n",
    "    variables = [v for v in variables if v in df.columns]\n",
    "    print('-'*50)\n",
    "    print(f\"Variables consideradas ({nombre_grupo}): \\n{variables}\")\n",
    "\n",
    "    # Conteo y proporción de nulos\n",
    "    nulos_totales = df[variables].isna().sum()\n",
    "    proporcion_nulos = df[variables].isna().mean() * 100\n",
    "\n",
    "    # Mostrar resumen\n",
    "    resumen = pd.DataFrame({\n",
    "        \"nulos\": nulos_totales,\n",
    "        \"porcentaje\": proporcion_nulos.round(2)\n",
    "    }).sort_values(\"porcentaje\", ascending=False)\n",
    "\n",
    "    print(\"\\nResumen de nulos por variable:\")\n",
    "    print(resumen)\n",
    "\n",
    "    # Filas con al menos un nulo en ese grupo\n",
    "    df[f\"nulos_{nombre_grupo}\"] = df[variables].isna().any(axis=1)\n",
    "    total_filas_nulas = df[f\"nulos_{nombre_grupo}\"].sum()\n",
    "    porcentaje_filas_nulas = df[f\"nulos_{nombre_grupo}\"].mean() * 100\n",
    "\n",
    "    print(f\"\\nFilas con al menos un nulo en {nombre_grupo}: {total_filas_nulas}\")\n",
    "    print(f\"Proporción total: {porcentaje_filas_nulas:.2f}%\")\n",
    "\n",
    "print('-'*50)\n",
    "print('Valores nulos')\n",
    "resumen_nulos(df, cognitivas, \"cognitivas\")\n",
    "resumen_nulos(df, volumen, \"volumen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputación\n",
      "--------------------------------------------------\n",
      "Variables numéricas para imputación (cognitivas):\n",
      "['CDRSB', 'MMSE', 'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR']\n",
      "✅ Imputación completada.\n",
      "\n",
      "📁 Archivo guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_cognitivas_imputadas.csv\n",
      "--------------------------------------------------\n",
      "Variables numéricas para imputación (volumen):\n",
      "['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
      "✅ Imputación completada.\n",
      "\n",
      "📁 Archivo guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_volumen_imputadas.csv\n"
     ]
    }
   ],
   "source": [
    "def imputar_y_normalizar(df, variables, nombre_grupo, out_dir=None):\n",
    "   \n",
    "    print('-'*50)\n",
    "    # Filtrar solo variables numéricas válidas\n",
    "    variables_num = [v for v in variables if v in df.columns and df[v].dtype.kind in \"iufc\"]\n",
    "    print(f\"Variables numéricas para imputación ({nombre_grupo}):\\n{variables_num}\")\n",
    "\n",
    "    # Subset de datos\n",
    "    datos = df[variables_num].copy()\n",
    "\n",
    "    # Imputación multivariada\n",
    "    # Modelo bayesiano iterativo para predecir valores faltantes en función de las demás variables.\n",
    "    imputer = IterativeImputer(random_state=42, max_iter=20, sample_posterior=True)\n",
    "    datos_imputados = imputer.fit_transform(datos)\n",
    "\n",
    "    # Convertir a DataFrame imputado\n",
    "    df_imputado = pd.DataFrame(datos_imputados, columns=variables_num, index=df.index)\n",
    "\n",
    "    # Reemplazar en el DataFrame original\n",
    "    for v in variables_num:\n",
    "        df[v] = df_imputado[v]\n",
    "\n",
    "    print(\"✅ Imputación completada.\")\n",
    "\n",
    "    # Normalización z-score\n",
    "    scaler = StandardScaler()\n",
    "    df_std = pd.DataFrame(\n",
    "        scaler.fit_transform(df[variables_num]),\n",
    "        columns=[v + \"_std\" for v in variables_num],\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    # Concatenar al DataFrame original\n",
    "    df = pd.concat([df, df_std], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "print('Imputación')\n",
    "df = imputar_y_normalizar(df, cognitivas, \"cognitivas\", OUT_DIR)\n",
    "df = imputar_y_normalizar(df, volumen, \"volumen\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a96fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categóricas\n",
    "generos = {'Male':1, 'Female':0}\n",
    "df['Sexo'] = df['PTGENDER'].map(generos)\n",
    "df['Sexo'].unique()\n",
    "\n",
    "df['Education'] = df['PTEDUCAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "915456b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "📁 DX con valores nulos:\n",
      "Registros con DX nulos: 28\n",
      "10.04% de los registros no tienen DX asignado.\n",
      "Diagnosticos nulos en las vistas: ['m30']\n"
     ]
    }
   ],
   "source": [
    "# DX con valores nulos\n",
    "print(\"-\" * 30)\n",
    "print(\"📁 DX con valores nulos:\")\n",
    "print(f\"Registros con DX nulos: {df['DX'].isna().sum()}\")\n",
    "porcentaje_nulo = df[\"DX\"].isna().mean() * 100\n",
    "print(f\"{porcentaje_nulo:.2f}% de los registros no tienen DX asignado.\")\n",
    "df_dx_nulo = df[df[\"DX\"].isna()]\n",
    "print(f\"Diagnosticos nulos en las vistas: {df_dx_nulo['VISCODE'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ca31707",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_dem = ['AGE', 'Sexo', 'Education']\n",
    "columnas_std = [col for col in df.columns if col.endswith(\"_std\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d5846",
   "metadata": {},
   "source": [
    "## Estandarización de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e79ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Plantilla base (más frecuente) ===\n",
    "TARGET_SHAPE = (160, 192, 192)\n",
    "TARGET_VOXEL = (1.2, 0.9375, 0.9375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eaa205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Procesamiento completo. Guardado en C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\n"
     ]
    }
   ],
   "source": [
    "# === Funciones auxiliares ===\n",
    "\n",
    "def normalize_intensity(data):\n",
    "    \"\"\"Normaliza intensidades tipo Z-score\"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    if std == 0:\n",
    "        return np.zeros_like(data)\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def resize_image(data, target_shape):\n",
    "    \"\"\"Redimensiona al shape más frecuente\"\"\"\n",
    "    return resize(data, target_shape, mode=\"constant\", preserve_range=True)\n",
    "\n",
    "\n",
    "def process_image(row):\n",
    "    \"\"\"\n",
    "    Lee la imagen NIfTI, normaliza y guarda en formato .npy\n",
    "    usando la ruta y nombre definidos en df['ruta_npy'].\n",
    "    \"\"\"\n",
    "    nifti_path = Path(row[\"ruta_abs\"])\n",
    "    npy_path = Path(row[\"ruta_npy\"])\n",
    "    \n",
    "    try:\n",
    "        img = nib.load(nifti_path)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        # --- Resize si no coincide con el target ---\n",
    "        if data.shape != TARGET_SHAPE:\n",
    "            data = resize_image(data, TARGET_SHAPE)\n",
    "\n",
    "        # --- Normalización de intensidades ---\n",
    "        data = normalize_intensity(data)\n",
    "\n",
    "        # --- Metadatos después del procesamiento ---\n",
    "        shape_proc = data.shape\n",
    "        mean_proc = float(np.mean(data))\n",
    "        std_proc = float(np.std(data))\n",
    "        \n",
    "\n",
    "        # --- Guardar como .npy ---\n",
    "        np.save(npy_path, data)\n",
    "\n",
    "        return {\n",
    "            \"sujeto_id\": row[\"sujeto_id\"],\n",
    "            \"VISCODE\": row[\"VISCODE\"],\n",
    "            \"DX\": row[\"DX\"],\n",
    "            \"ruta_npy\": str(npy_path),\n",
    "            \"fecha\": row['Fecha'],\n",
    "\n",
    "            \"shape\": shape_proc,\n",
    "            \"mean_intensity\": mean_proc,\n",
    "            \"std_intensity\": std_proc,\n",
    "\n",
    "            \"estado\": \"OK\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error con {nifti_path.name}: {e}\")\n",
    "        return {\n",
    "            \"sujeto_id\": row[\"sujeto_id\"],\n",
    "            \"VISCODE\": row[\"VISCODE\"],\n",
    "            \"DX\": row[\"DX\"],\n",
    "            \"ruta_npy\": str(npy_path),\n",
    "            \"procesado\": False,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# === Aplicar a todas las filas ===\n",
    "\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    res = process_image(row)\n",
    "    results.append(res)\n",
    "\n",
    "df_npy = pd.DataFrame(results)\n",
    "\n",
    "# === Guardar log final ===\n",
    "df_npy.to_csv(OUT_DIR / \"registro_imagenes_procesadas.csv\", index=False)\n",
    "print(f\"✅ Procesamiento completo. Guardado en {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7f609",
   "metadata": {},
   "source": [
    "## Crear archivos de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2682ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sujeto_id', 'id_visita', 'Fecha', 'VISCODE', 'vis_month',\n",
       "       'is_dementia', 'label_progresion', 'ruta_npy', 'AGE', 'Sexo',\n",
       "       'Education', 'CDRSB_std', 'MMSE_std', 'ADAS13_std', 'FAQ_std',\n",
       "       'RAVLT_immediate_std', 'RAVLT_learning_std', 'RAVLT_forgetting_std',\n",
       "       'DIGITSCOR_std', 'TRABSCOR_std', 'Ventricles_std', 'Hippocampus_std',\n",
       "       'WholeBrain_std', 'Entorhinal_std', 'Fusiform_std', 'MidTemp_std',\n",
       "       'ICV_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributos = pd.concat([df[columnas_id], df[columnas_dem], df[columnas_std]], axis=1)\n",
    "atributos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "277b75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 279 entries, 0 to 278\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   sujeto_id             279 non-null    object        \n",
      " 1   id_visita             279 non-null    object        \n",
      " 2   Fecha                 279 non-null    datetime64[ns]\n",
      " 3   VISCODE               279 non-null    object        \n",
      " 4   vis_month             279 non-null    int64         \n",
      " 5   is_dementia           251 non-null    float64       \n",
      " 6   label_progresion      279 non-null    int64         \n",
      " 7   ruta_npy              279 non-null    object        \n",
      " 8   AGE                   279 non-null    float64       \n",
      " 9   Sexo                  279 non-null    int64         \n",
      " 10  Education             279 non-null    int64         \n",
      " 11  CDRSB_std             279 non-null    float64       \n",
      " 12  MMSE_std              279 non-null    float64       \n",
      " 13  ADAS13_std            279 non-null    float64       \n",
      " 14  FAQ_std               279 non-null    float64       \n",
      " 15  RAVLT_immediate_std   279 non-null    float64       \n",
      " 16  RAVLT_learning_std    279 non-null    float64       \n",
      " 17  RAVLT_forgetting_std  279 non-null    float64       \n",
      " 18  DIGITSCOR_std         279 non-null    float64       \n",
      " 19  TRABSCOR_std          279 non-null    float64       \n",
      " 20  Ventricles_std        279 non-null    float64       \n",
      " 21  Hippocampus_std       279 non-null    float64       \n",
      " 22  WholeBrain_std        279 non-null    float64       \n",
      " 23  Entorhinal_std        279 non-null    float64       \n",
      " 24  Fusiform_std          279 non-null    float64       \n",
      " 25  MidTemp_std           279 non-null    float64       \n",
      " 26  ICV_std               279 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(18), int64(4), object(4)\n",
      "memory usage: 59.0+ KB\n"
     ]
    }
   ],
   "source": [
    "atributos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb33c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset final guardado en C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\\Data\\atributos.csv\n"
     ]
    }
   ],
   "source": [
    "FINAL_PATH = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\\Data\\atributos.csv\")\n",
    "atributos.to_csv(FINAL_PATH, index=False)\n",
    "print(f\"✅ Dataset final guardado en {FINAL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACHINE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
