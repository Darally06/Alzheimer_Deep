{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15ce3aa",
   "metadata": {},
   "source": [
    "# **PREPROCESAMIENTO DE IM√ÅGENES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136291cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f52e2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Config] Rutas\n",
    "# Ajusta estas rutas seg√∫n tu estructura\n",
    "BASE_IMAGES_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\Datos\\IMAGES\")   \n",
    "NOTEBOOKS_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\")      \n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_csv(\"./Data/ADNI_Images.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64003c37",
   "metadata": {},
   "source": [
    "## Rutas a archivos y estandarizaci√≥n de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0a9ea",
   "metadata": {},
   "source": [
    "_____________\n",
    "* 1. Verificar y normalizar rutas a archivos .nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ac2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar rutas a los archivos nii\n",
    "def normalize_path(p):\n",
    "    # convierte rutas relativas con .. y / a una Path absoluta\n",
    "    p = str(p)\n",
    "    # Reemplaza barras si vienen con may√∫sculas, espacios extra, etc.\n",
    "    return Path(p.replace(\"/\", os.sep)).resolve()\n",
    "df['ruta_abs'] = df['ruta'].apply(lambda p: normalize_path(p) if pd.notnull(p) else p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e8c71",
   "metadata": {},
   "source": [
    "________\n",
    "* 2. Crear identificadores y nombres de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad459148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos campos clave\n",
    "df['sujeto_id'] = df['sujeto_id'].astype(str)\n",
    "df['VISCODE'] = df['VISCODE'].astype(str)\n",
    "# EXAMDATE -> intentar parsear (si ya es datetime, no cambia)\n",
    "def parse_date(x):\n",
    "    if pd.isnull(x): \n",
    "        return pd.NaT\n",
    "    if isinstance(x, (datetime, pd.Timestamp)):\n",
    "        return pd.to_datetime(x)\n",
    "    # probar distintos formatos comunes\n",
    "    for fmt in (\"%Y-%m-%d\", \"%Y/%m/%d\", \"%d-%m-%Y\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%dT%H:%M:%S\"):\n",
    "        try:\n",
    "            return pd.to_datetime(x, format=fmt)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.to_datetime(x, errors='coerce')\n",
    "\n",
    "df['Fecha'] = df['EXAMDATE'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba859da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_visita = sujetoid_VISCODE\n",
    "df['id_visita'] = df['sujeto_id'] + \"_\" + df['VISCODE']\n",
    "# fname_out (sin subcarpetas): sujetoid_EXAMDATE_VISCODE_archivoSinExt.npy\n",
    "def safe_fname(s):\n",
    "    # quita espacios, reemplaza / : etc\n",
    "    return \"\".join(c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in s)\n",
    "\n",
    "def make_output_fname(row):\n",
    "    subj = row['sujeto_id']\n",
    "    vis = row['VISCODE']\n",
    "    examdate = row['Fecha']\n",
    "    exam_str = examdate.strftime(\"%Y%m%d\") if pd.notnull(examdate) else \"noDate\"\n",
    "    arch = Path(row['archivo']).stem\n",
    "    fname = f\"{subj}_{exam_str}_{vis}_{arch}.npy\"\n",
    "    return safe_fname(fname)\n",
    "\n",
    "df['fname_out'] = df.apply(make_output_fname, axis=1)\n",
    "df['ruta_npy'] = df['fname_out'].apply(lambda s: OUT_DIR / s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7e63d",
   "metadata": {},
   "source": [
    "____________\n",
    "* 3. Construir etiquetas binarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31a0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos mapa VISCODE -> meses\n",
    "viscode_to_month = {'bl':0, 'm06':6, 'm12':12, 'm18':18, 'm24':24, 'm30':30, 'm36':36}\n",
    "df['vis_month'] = df['VISCODE'].map(viscode_to_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfedc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dx_is_dementia(dx):\n",
    "    if pd.isnull(dx):\n",
    "        return np.nan\n",
    "    s = str(dx).lower()\n",
    "    if 'dementia' in s:\n",
    "        return 1\n",
    "    if 'mci' in s:\n",
    "        return 0\n",
    "    return np.nan\n",
    "df['is_dementia'] = df['DX'].apply(dx_is_dementia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8180b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando labels por sujeto: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:00<00:00, 206.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels por sujeto (ejemplo):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sujeto_id</th>\n",
       "      <th>label_progresion</th>\n",
       "      <th>conversion_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007_S_0101</td>\n",
       "      <td>1</td>\n",
       "      <td>(m24, 24, 2007-12-12 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007_S_0128</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-08-20 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007_S_0249</td>\n",
       "      <td>1</td>\n",
       "      <td>(m12, 12, 2007-04-03 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>013_S_0240</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-10-31 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>014_S_0169</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>018_S_0057</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-08-21 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>018_S_0080</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>018_S_0087</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>018_S_0142</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>018_S_0155</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sujeto_id  label_progresion                 conversion_info\n",
       "0  007_S_0101                 1  (m24, 24, 2007-12-12 00:00:00)\n",
       "1  007_S_0128                 1  (m18, 18, 2007-08-20 00:00:00)\n",
       "2  007_S_0249                 1  (m12, 12, 2007-04-03 00:00:00)\n",
       "3  013_S_0240                 1  (m18, 18, 2007-10-31 00:00:00)\n",
       "4  014_S_0169                 0                            None\n",
       "5  018_S_0057                 1  (m18, 18, 2007-08-21 00:00:00)\n",
       "6  018_S_0080                 0                            None\n",
       "7  018_S_0087                 0                            None\n",
       "8  018_S_0142                 0                            None\n",
       "9  018_S_0155                 0                            None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construir label por sujeto:\n",
    "# Regla: si sujeto presenta transici√≥n de non-dementia -> dementia en alg√∫n vis <=36 meses -> label 1.\n",
    "# Implementaci√≥n simplificada:\n",
    "labels = []\n",
    "subjects = df['sujeto_id'].unique()\n",
    "for subj in tqdm(subjects, desc=\"Calculando labels por sujeto\"):\n",
    "    subdf = df[df['sujeto_id']==subj].copy()\n",
    "    # orden por vis_month (si NaN, orden por Fecha)\n",
    "    if subdf['vis_month'].notna().any():\n",
    "        subdf = subdf.sort_values(by=['vis_month','Fecha'])\n",
    "    else:\n",
    "        subdf = subdf.sort_values(by='')\n",
    "    # buscamos primer visita con is_dementia==1 y su mes\n",
    "    # y primer visita con is_dementia==0 (baseline non-dementia)\n",
    "    baseline_non_d = subdf[subdf['is_dementia']==0]\n",
    "    first_non_d = None\n",
    "    if not baseline_non_d.empty:\n",
    "        # preferir VISCODE 'bl' si existe\n",
    "        if (baseline_non_d['VISCODE'].str.lower()=='bl').any():\n",
    "            first_non_d = baseline_non_d[baseline_non_d['VISCODE'].str.lower()=='bl'].iloc[0]\n",
    "        else:\n",
    "            first_non_d = baseline_non_d.iloc[0]\n",
    "    # buscar conversion\n",
    "    converted = False\n",
    "    conversion_info = None\n",
    "    # consideramos cualquier visita con is_dementia==1 y vis_month <= 36\n",
    "    dem_vis = subdf[subdf['is_dementia']==1]\n",
    "    if not dem_vis.empty:\n",
    "        # si hay baseline non-dementia, la conversi√≥n debe ocurrir tras baseline\n",
    "        if first_non_d is not None:\n",
    "            # buscar dem_vis cuya month >= baseline month y <=36\n",
    "            base_month = first_non_d.get('vis_month', 0) if pd.notnull(first_non_d.get('vis_month', np.nan)) else 0\n",
    "            # candidate dem_vis posteriores\n",
    "            for _, r in dem_vis.iterrows():\n",
    "                month = r.get('vis_month', np.nan)\n",
    "                if pd.isna(month):\n",
    "                    # si no hay month, intentar por fecha diff\n",
    "                    if pd.notnull(first_non_d['Fecha']) and pd.notnull(r['Fecha']):\n",
    "                        diff_months = (r['Fecha'].year - first_non_d['Fecha'].year)*12 + (r['Fecha'].month - first_non_d['Fecha'].month)\n",
    "                        month = diff_months\n",
    "                # now check range\n",
    "                if pd.notnull(month) and (month >= base_month) and (month <= 36):\n",
    "                    converted = True\n",
    "                    conversion_info = (r['VISCODE'], month, r['Fecha'])\n",
    "                    break\n",
    "        else:\n",
    "            # No baseline non-dementia conocido: fallback -> if any dem_vis within <=36 -> label may be ambiguous:\n",
    "            # we'll mark converted if there's any dem_vis with vis_month<=36\n",
    "            for _, r in dem_vis.iterrows():\n",
    "                month = r.get('vis_month', np.nan)\n",
    "                if pd.notnull(month) and month <= 36:\n",
    "                    converted = True\n",
    "                    conversion_info = (r['VISCODE'], month, r['Fecha'])\n",
    "                    break\n",
    "    # Save label for all rows of this subject (we attach label at image-row level later)\n",
    "    labels.append({'sujeto_id': subj, 'label_progresion': int(converted), 'conversion_info': conversion_info})\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "print(\"Labels por sujeto (ejemplo):\")\n",
    "display(labels_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7c73cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen labels (por sujeto):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_progresion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count\n",
       "label_progresion       \n",
       "0                    29\n",
       "1                    22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resumen de labels\n",
    "# Merge back al df (por sujeto_id)\n",
    "df = df.merge(labels_df[['sujeto_id','label_progresion']], on='sujeto_id', how='left')\n",
    "\n",
    "print(\"Resumen labels (por sujeto):\")\n",
    "display(labels_df['label_progresion'].value_counts(dropna=False).to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487f0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables y labels \n",
    "columnas_id = ['sujeto_id', 'id_visita', 'Fecha', 'VISCODE', 'vis_month', 'is_dementia', 'label_progresion', 'ruta_npy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766f473",
   "metadata": {},
   "source": [
    "## Valores nulos e imputaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786153b",
   "metadata": {},
   "source": [
    "____________\n",
    "* 1. Exploraci√≥n de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf68150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de variables nulas \n",
    "cognitivas = [\n",
    "    \"CDRSB\", #\"Suma de cajas del Clinical Dementia Rating (CDR); mide la severidad de la demencia.\",\n",
    "    \"MMSE\", #\"Mini-Mental State Examination; evaluaci√≥n global del estado cognitivo (m√°x. 30 puntos).\",\n",
    "    \"ADAS13\", #\"Alzheimer‚Äôs Disease Assessment Scale ‚Äì 13 √≠tems; mide deterioro cognitivo en Alzheimer.\",\n",
    "    \"FAQ\", #\"Functional Activities Questionnaire; eval√∫a la capacidad funcional en actividades diarias.\",\n",
    "    \"RAVLT_immediate\", # \"Puntuaci√≥n inmediata en la prueba verbal de aprendizaje (Rey Auditory Verbal Learning Test).\",\n",
    "    \"RAVLT_learning\", # \"Puntuaci√≥n de aprendizaje acumulado en RAVLT; mide retenci√≥n verbal.\",\n",
    "    \"RAVLT_forgetting\", # \"√çndice de olvido en RAVLT; diferencia entre aprendizaje y recuerdo tard√≠o.\",\n",
    "    \"DIGITSCOR\", #\"Digit Span Score; mide memoria de trabajo y atenci√≥n mediante secuencias num√©ricas.\",\n",
    "    \"TRABSCOR\", # \"Trail Making Test B Score; eval√∫a funci√≥n ejecutiva y flexibilidad cognitiva.\",\n",
    "]\n",
    "volumen = [\n",
    "    \"Ventricles\", # \"Volumen de los ventr√≠culos cerebrales; puede indicar atrofia cerebral.\",\n",
    "    \"Hippocampus\", # \"Volumen del hipocampo; clave en memoria y afectado en Alzheimer.\",\n",
    "    \"WholeBrain\", # \"Volumen total del cerebro; √∫til para evaluar atrofia global.\",\n",
    "    \"Entorhinal\", # \"Volumen de la corteza entorrinal; regi√≥n afectada tempranamente en Alzheimer.\",\n",
    "    \"Fusiform\", #\"Volumen del giro fusiforme; relacionado con reconocimiento visual.\",\n",
    "    \"MidTemp\", # \"Volumen del l√≥bulo temporal medio; implicado en memoria y procesamiento auditivo.\",\n",
    "    \"ICV\", #\"Volumen intracraneal total; usado para normalizar medidas volum√©tricas.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d4132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Valores nulos\n",
      "--------------------------------------------------\n",
      "Variables consideradas (cognitivas): \n",
      "['CDRSB', 'MMSE', 'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR']\n",
      "\n",
      "Resumen de nulos por variable:\n",
      "                  nulos  porcentaje\n",
      "FAQ                  31       11.11\n",
      "TRABSCOR             31       11.11\n",
      "CDRSB                30       10.75\n",
      "RAVLT_forgetting     30       10.75\n",
      "ADAS13               29       10.39\n",
      "RAVLT_immediate      29       10.39\n",
      "RAVLT_learning       29       10.39\n",
      "DIGITSCOR            29       10.39\n",
      "MMSE                 28       10.04\n",
      "\n",
      "Filas con al menos un nulo en cognitivas: 38\n",
      "Proporci√≥n total: 13.62%\n",
      "--------------------------------------------------\n",
      "Variables consideradas (volumen): \n",
      "['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
      "\n",
      "Resumen de nulos por variable:\n",
      "             nulos  porcentaje\n",
      "Hippocampus     67       24.01\n",
      "Entorhinal      67       24.01\n",
      "Fusiform        67       24.01\n",
      "MidTemp         67       24.01\n",
      "Ventricles      38       13.62\n",
      "WholeBrain      38       13.62\n",
      "ICV             38       13.62\n",
      "\n",
      "Filas con al menos un nulo en volumen: 67\n",
      "Proporci√≥n total: 24.01%\n"
     ]
    }
   ],
   "source": [
    "def resumen_nulos(df, variables, nombre_grupo):\n",
    "    # Asegurar que las variables existan en el DataFrame\n",
    "    variables = [v for v in variables if v in df.columns]\n",
    "    print('-'*50)\n",
    "    print(f\"Variables consideradas ({nombre_grupo}): \\n{variables}\")\n",
    "\n",
    "    # Conteo y proporci√≥n de nulos\n",
    "    nulos_totales = df[variables].isna().sum()\n",
    "    proporcion_nulos = df[variables].isna().mean() * 100\n",
    "\n",
    "    # Mostrar resumen\n",
    "    resumen = pd.DataFrame({\n",
    "        \"nulos\": nulos_totales,\n",
    "        \"porcentaje\": proporcion_nulos.round(2)\n",
    "    }).sort_values(\"porcentaje\", ascending=False)\n",
    "\n",
    "    print(\"\\nResumen de nulos por variable:\")\n",
    "    print(resumen)\n",
    "\n",
    "    # Filas con al menos un nulo en ese grupo\n",
    "    df[f\"nulos_{nombre_grupo}\"] = df[variables].isna().any(axis=1)\n",
    "    total_filas_nulas = df[f\"nulos_{nombre_grupo}\"].sum()\n",
    "    porcentaje_filas_nulas = df[f\"nulos_{nombre_grupo}\"].mean() * 100\n",
    "\n",
    "    print(f\"\\nFilas con al menos un nulo en {nombre_grupo}: {total_filas_nulas}\")\n",
    "    print(f\"Proporci√≥n total: {porcentaje_filas_nulas:.2f}%\")\n",
    "\n",
    "print('-'*50)\n",
    "print('Valores nulos')\n",
    "resumen_nulos(df, cognitivas, \"cognitivas\")\n",
    "resumen_nulos(df, volumen, \"volumen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputaci√≥n\n",
      "--------------------------------------------------\n",
      "Variables num√©ricas para imputaci√≥n (cognitivas):\n",
      "['CDRSB', 'MMSE', 'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR']\n",
      "‚úÖ Imputaci√≥n completada.\n",
      "\n",
      "üìÅ Archivo guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_cognitivas_imputadas.csv\n",
      "--------------------------------------------------\n",
      "Variables num√©ricas para imputaci√≥n (volumen):\n",
      "['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
      "‚úÖ Imputaci√≥n completada.\n",
      "\n",
      "üìÅ Archivo guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_volumen_imputadas.csv\n"
     ]
    }
   ],
   "source": [
    "def imputar_y_normalizar(df, variables, nombre_grupo, out_dir=None):\n",
    "   \n",
    "    print('-'*50)\n",
    "    # Filtrar solo variables num√©ricas v√°lidas\n",
    "    variables_num = [v for v in variables if v in df.columns and df[v].dtype.kind in \"iufc\"]\n",
    "    print(f\"Variables num√©ricas para imputaci√≥n ({nombre_grupo}):\\n{variables_num}\")\n",
    "\n",
    "    # Subset de datos\n",
    "    datos = df[variables_num].copy()\n",
    "\n",
    "    # Imputaci√≥n multivariada\n",
    "    # Modelo bayesiano iterativo para predecir valores faltantes en funci√≥n de las dem√°s variables.\n",
    "    imputer = IterativeImputer(random_state=42, max_iter=20, sample_posterior=True)\n",
    "    datos_imputados = imputer.fit_transform(datos)\n",
    "\n",
    "    # Convertir a DataFrame imputado\n",
    "    df_imputado = pd.DataFrame(datos_imputados, columns=variables_num, index=df.index)\n",
    "\n",
    "    # Reemplazar en el DataFrame original\n",
    "    for v in variables_num:\n",
    "        df[v] = df_imputado[v]\n",
    "\n",
    "    print(\"‚úÖ Imputaci√≥n completada.\")\n",
    "\n",
    "    # Normalizaci√≥n z-score\n",
    "    scaler = StandardScaler()\n",
    "    df_std = pd.DataFrame(\n",
    "        scaler.fit_transform(df[variables_num]),\n",
    "        columns=[v + \"_std\" for v in variables_num],\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    # Concatenar al DataFrame original\n",
    "    df = pd.concat([df, df_std], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "print('Imputaci√≥n')\n",
    "df = imputar_y_normalizar(df, cognitivas, \"cognitivas\", OUT_DIR)\n",
    "df = imputar_y_normalizar(df, volumen, \"volumen\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a96fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categ√≥ricas\n",
    "generos = {'Male':1, 'Female':0}\n",
    "df['Sexo'] = df['PTGENDER'].map(generos)\n",
    "df['Sexo'].unique()\n",
    "\n",
    "df['Education'] = df['PTEDUCAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "915456b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "üìÅ DX con valores nulos:\n",
      "Registros con DX nulos: 28\n",
      "10.04% de los registros no tienen DX asignado.\n",
      "Diagnosticos nulos en las vistas: ['m30']\n"
     ]
    }
   ],
   "source": [
    "# DX con valores nulos\n",
    "print(\"-\" * 30)\n",
    "print(\"üìÅ DX con valores nulos:\")\n",
    "print(f\"Registros con DX nulos: {df['DX'].isna().sum()}\")\n",
    "porcentaje_nulo = df[\"DX\"].isna().mean() * 100\n",
    "print(f\"{porcentaje_nulo:.2f}% de los registros no tienen DX asignado.\")\n",
    "df_dx_nulo = df[df[\"DX\"].isna()]\n",
    "print(f\"Diagnosticos nulos en las vistas: {df_dx_nulo['VISCODE'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ca31707",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_dem = ['AGE', 'Sexo', 'Education']\n",
    "columnas_std = [col for col in df.columns if col.endswith(\"_std\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d5846",
   "metadata": {},
   "source": [
    "## Estandarizaci√≥n de las im√°genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e79ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Plantilla base (m√°s frecuente) ===\n",
    "TARGET_SHAPE = (160, 192, 192)\n",
    "TARGET_VOXEL = (1.2, 0.9375, 0.9375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eaa205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Procesamiento completo. Guardado en C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\n"
     ]
    }
   ],
   "source": [
    "# === Funciones auxiliares ===\n",
    "\n",
    "def normalize_intensity(data):\n",
    "    \"\"\"Normaliza intensidades tipo Z-score\"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    if std == 0:\n",
    "        return np.zeros_like(data)\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def resize_image(data, target_shape):\n",
    "    \"\"\"Redimensiona al shape m√°s frecuente\"\"\"\n",
    "    return resize(data, target_shape, mode=\"constant\", preserve_range=True)\n",
    "\n",
    "\n",
    "def process_image(row):\n",
    "    \"\"\"\n",
    "    Lee la imagen NIfTI, normaliza y guarda en formato .npy\n",
    "    usando la ruta y nombre definidos en df['ruta_npy'].\n",
    "    \"\"\"\n",
    "    nifti_path = Path(row[\"ruta_abs\"])\n",
    "    npy_path = Path(row[\"ruta_npy\"])\n",
    "    \n",
    "    try:\n",
    "        img = nib.load(nifti_path)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        # --- Resize si no coincide con el target ---\n",
    "        if data.shape != TARGET_SHAPE:\n",
    "            data = resize_image(data, TARGET_SHAPE)\n",
    "\n",
    "        # --- Normalizaci√≥n de intensidades ---\n",
    "        data = normalize_intensity(data)\n",
    "\n",
    "        # --- Metadatos despu√©s del procesamiento ---\n",
    "        shape_proc = data.shape\n",
    "        mean_proc = float(np.mean(data))\n",
    "        std_proc = float(np.std(data))\n",
    "        \n",
    "\n",
    "        # --- Guardar como .npy ---\n",
    "        np.save(npy_path, data)\n",
    "\n",
    "        return {\n",
    "            \"sujeto_id\": row[\"sujeto_id\"],\n",
    "            \"VISCODE\": row[\"VISCODE\"],\n",
    "            \"DX\": row[\"DX\"],\n",
    "            \"ruta_npy\": str(npy_path),\n",
    "            \"fecha\": row['Fecha'],\n",
    "\n",
    "            \"shape\": shape_proc,\n",
    "            \"mean_intensity\": mean_proc,\n",
    "            \"std_intensity\": std_proc,\n",
    "\n",
    "            \"estado\": \"OK\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error con {nifti_path.name}: {e}\")\n",
    "        return {\n",
    "            \"sujeto_id\": row[\"sujeto_id\"],\n",
    "            \"VISCODE\": row[\"VISCODE\"],\n",
    "            \"DX\": row[\"DX\"],\n",
    "            \"ruta_npy\": str(npy_path),\n",
    "            \"procesado\": False,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# === Aplicar a todas las filas ===\n",
    "\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    res = process_image(row)\n",
    "    results.append(res)\n",
    "\n",
    "df_npy = pd.DataFrame(results)\n",
    "\n",
    "# === Guardar log final ===\n",
    "df_npy.to_csv(OUT_DIR / \"registro_imagenes_procesadas.csv\", index=False)\n",
    "print(f\"‚úÖ Procesamiento completo. Guardado en {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7f609",
   "metadata": {},
   "source": [
    "## Crear archivos de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2682ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sujeto_id', 'id_visita', 'Fecha', 'VISCODE', 'vis_month',\n",
       "       'is_dementia', 'label_progresion', 'ruta_npy', 'AGE', 'Sexo',\n",
       "       'Education', 'CDRSB_std', 'MMSE_std', 'ADAS13_std', 'FAQ_std',\n",
       "       'RAVLT_immediate_std', 'RAVLT_learning_std', 'RAVLT_forgetting_std',\n",
       "       'DIGITSCOR_std', 'TRABSCOR_std', 'Ventricles_std', 'Hippocampus_std',\n",
       "       'WholeBrain_std', 'Entorhinal_std', 'Fusiform_std', 'MidTemp_std',\n",
       "       'ICV_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributos = pd.concat([df[columnas_id], df[columnas_dem], df[columnas_std]], axis=1)\n",
    "atributos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "277b75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 279 entries, 0 to 278\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   sujeto_id             279 non-null    object        \n",
      " 1   id_visita             279 non-null    object        \n",
      " 2   Fecha                 279 non-null    datetime64[ns]\n",
      " 3   VISCODE               279 non-null    object        \n",
      " 4   vis_month             279 non-null    int64         \n",
      " 5   is_dementia           251 non-null    float64       \n",
      " 6   label_progresion      279 non-null    int64         \n",
      " 7   ruta_npy              279 non-null    object        \n",
      " 8   AGE                   279 non-null    float64       \n",
      " 9   Sexo                  279 non-null    int64         \n",
      " 10  Education             279 non-null    int64         \n",
      " 11  CDRSB_std             279 non-null    float64       \n",
      " 12  MMSE_std              279 non-null    float64       \n",
      " 13  ADAS13_std            279 non-null    float64       \n",
      " 14  FAQ_std               279 non-null    float64       \n",
      " 15  RAVLT_immediate_std   279 non-null    float64       \n",
      " 16  RAVLT_learning_std    279 non-null    float64       \n",
      " 17  RAVLT_forgetting_std  279 non-null    float64       \n",
      " 18  DIGITSCOR_std         279 non-null    float64       \n",
      " 19  TRABSCOR_std          279 non-null    float64       \n",
      " 20  Ventricles_std        279 non-null    float64       \n",
      " 21  Hippocampus_std       279 non-null    float64       \n",
      " 22  WholeBrain_std        279 non-null    float64       \n",
      " 23  Entorhinal_std        279 non-null    float64       \n",
      " 24  Fusiform_std          279 non-null    float64       \n",
      " 25  MidTemp_std           279 non-null    float64       \n",
      " 26  ICV_std               279 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(18), int64(4), object(4)\n",
      "memory usage: 59.0+ KB\n"
     ]
    }
   ],
   "source": [
    "atributos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb33c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset final guardado en C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\\Data\\atributos.csv\n"
     ]
    }
   ],
   "source": [
    "FINAL_PATH = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\\Data\\atributos.csv\")\n",
    "atributos.to_csv(FINAL_PATH, index=False)\n",
    "print(f\"‚úÖ Dataset final guardado en {FINAL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACHINE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
