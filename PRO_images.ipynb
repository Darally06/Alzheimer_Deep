{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15ce3aa",
   "metadata": {},
   "source": [
    "# **PREPROCESAMIENTO DE IM√ÅGENES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "136291cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f52e2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Config] Rutas\n",
    "# Ajusta estas rutas seg√∫n tu estructura\n",
    "BASE_IMAGES_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\Datos\\IMAGES\")   # ya usado en df['ruta'] (puede ser relativo)\n",
    "NOTEBOOKS_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\")      # donde dejaremos los .npy despu√©s\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_csv(\"../Datos/Clinical/ADNI_Images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a0735e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 35)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64003c37",
   "metadata": {},
   "source": [
    "## Rutas a archivos y estandarizaci√≥n de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0a9ea",
   "metadata": {},
   "source": [
    "_____________\n",
    "* 1. Verificar y normalizar rutas a archivos .nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36ac2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar rutas a los archivos nii\n",
    "def normalize_path(p):\n",
    "    # convierte rutas relativas con .. y / a una Path absoluta\n",
    "    p = str(p)\n",
    "    # Reemplaza barras si vienen con may√∫sculas, espacios extra, etc.\n",
    "    return Path(p.replace(\"/\", os.sep)).resolve()\n",
    "df['ruta_abs'] = df['ruta'].apply(lambda p: normalize_path(p) if pd.notnull(p) else p)\n",
    "df['archivo'] = df['archivo'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e8c71",
   "metadata": {},
   "source": [
    "________\n",
    "* 2. Crear identificadores y nombres de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad459148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos campos clave\n",
    "df['sujeto_id'] = df['sujeto_id'].astype(str)\n",
    "df['VISCODE'] = df['VISCODE'].astype(str)\n",
    "# EXAMDATE -> intentar parsear (si ya es datetime, no cambia)\n",
    "def parse_date(x):\n",
    "    if pd.isnull(x): \n",
    "        return pd.NaT\n",
    "    if isinstance(x, (datetime, pd.Timestamp)):\n",
    "        return pd.to_datetime(x)\n",
    "    # probar distintos formatos comunes\n",
    "    for fmt in (\"%Y-%m-%d\", \"%Y/%m/%d\", \"%d-%m-%Y\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%dT%H:%M:%S\"):\n",
    "        try:\n",
    "            return pd.to_datetime(x, format=fmt)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.to_datetime(x, errors='coerce')\n",
    "\n",
    "df['EXAMDATE_parsed'] = df['EXAMDATE'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba859da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_visita = sujetoid_VISCODE\n",
    "df['id_visita'] = df['sujeto_id'] + \"_\" + df['VISCODE']\n",
    "# fname_out (sin subcarpetas): sujetoid_EXAMDATE_VISCODE_archivoSinExt.npy\n",
    "def safe_fname(s):\n",
    "    # quita espacios, reemplaza / : etc\n",
    "    return \"\".join(c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in s)\n",
    "\n",
    "def make_output_fname(row):\n",
    "    subj = row['sujeto_id']\n",
    "    vis = row['VISCODE']\n",
    "    examdate = row['EXAMDATE_parsed']\n",
    "    exam_str = examdate.strftime(\"%Y%m%d\") if pd.notnull(examdate) else \"noDate\"\n",
    "    arch = Path(row['archivo']).stem\n",
    "    fname = f\"{subj}_{exam_str}_{vis}_{arch}.npy\"\n",
    "    return safe_fname(fname)\n",
    "\n",
    "df['fname_out'] = df.apply(make_output_fname, axis=1)\n",
    "df['ruta_npy'] = df['fname_out'].apply(lambda s: OUT_DIR / s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98d40785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest preliminar guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_preprocesamiento.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardamos manifest preliminar (sin procesar im√°genes a√∫n)\n",
    "manifest_pre = df[['sujeto_id','id_visita','VISCODE','EXAMDATE','EXAMDATE_parsed','archivo','ruta','ruta_abs','ruta_npy','DX']]\n",
    "manifest_pre.to_csv(OUT_DIR / \"manifest_preprocesamiento.csv\", index=False)\n",
    "print(\"Manifest preliminar guardado en:\", OUT_DIR / \"manifest_preprocesamiento.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7e63d",
   "metadata": {},
   "source": [
    "____________\n",
    "* 3. Construir etiquetas binarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d31a0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos mapa VISCODE -> meses\n",
    "viscode_to_month = {'bl':0, 'm06':6, 'm12':12, 'm18':18, 'm24':24, 'm30':30, 'm36':36}\n",
    "df['vis_month'] = df['VISCODE'].map(viscode_to_month)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dfedc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dx_is_dementia(dx):\n",
    "    if pd.isnull(dx):\n",
    "        return np.nan\n",
    "    s = str(dx).lower()\n",
    "    if 'dementia' in s:\n",
    "        return 1\n",
    "    if 'mci' in s:\n",
    "        return 0\n",
    "    return np.nan\n",
    "df['is_dementia'] = df['DX'].apply(dx_is_dementia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8180b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando labels por sujeto: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53/53 [00:00<00:00, 262.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels por sujeto (ejemplo):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sujeto_id</th>\n",
       "      <th>label_progresion</th>\n",
       "      <th>conversion_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007_S_0101</td>\n",
       "      <td>1</td>\n",
       "      <td>(m24, 24, 2007-12-12 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007_S_0128</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-08-20 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007_S_0249</td>\n",
       "      <td>1</td>\n",
       "      <td>(m12, 12, 2007-04-03 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>013_S_0240</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-10-31 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>014_S_0169</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>018_S_0057</td>\n",
       "      <td>1</td>\n",
       "      <td>(m18, 18, 2007-08-21 00:00:00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>018_S_0080</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>018_S_0087</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>018_S_0103</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>018_S_0142</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sujeto_id  label_progresion                 conversion_info\n",
       "0  007_S_0101                 1  (m24, 24, 2007-12-12 00:00:00)\n",
       "1  007_S_0128                 1  (m18, 18, 2007-08-20 00:00:00)\n",
       "2  007_S_0249                 1  (m12, 12, 2007-04-03 00:00:00)\n",
       "3  013_S_0240                 1  (m18, 18, 2007-10-31 00:00:00)\n",
       "4  014_S_0169                 0                            None\n",
       "5  018_S_0057                 1  (m18, 18, 2007-08-21 00:00:00)\n",
       "6  018_S_0080                 0                            None\n",
       "7  018_S_0087                 0                            None\n",
       "8  018_S_0103                 0                            None\n",
       "9  018_S_0142                 0                            None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construir label por sujeto:\n",
    "# Regla: si sujeto presenta transici√≥n de non-dementia -> dementia en alg√∫n vis <=36 meses -> label 1.\n",
    "# Implementaci√≥n simplificada:\n",
    "labels = []\n",
    "subjects = df['sujeto_id'].unique()\n",
    "for subj in tqdm(subjects, desc=\"Calculando labels por sujeto\"):\n",
    "    subdf = df[df['sujeto_id']==subj].copy()\n",
    "    # orden por vis_month (si NaN, orden por EXAMDATE_parsed)\n",
    "    if subdf['vis_month'].notna().any():\n",
    "        subdf = subdf.sort_values(by=['vis_month','EXAMDATE_parsed'])\n",
    "    else:\n",
    "        subdf = subdf.sort_values(by='EXAMDATE_parsed')\n",
    "    # buscamos primer visita con is_dementia==1 y su mes\n",
    "    # y primer visita con is_dementia==0 (baseline non-dementia)\n",
    "    baseline_non_d = subdf[subdf['is_dementia']==0]\n",
    "    first_non_d = None\n",
    "    if not baseline_non_d.empty:\n",
    "        # preferir VISCODE 'bl' si existe\n",
    "        if (baseline_non_d['VISCODE'].str.lower()=='bl').any():\n",
    "            first_non_d = baseline_non_d[baseline_non_d['VISCODE'].str.lower()=='bl'].iloc[0]\n",
    "        else:\n",
    "            first_non_d = baseline_non_d.iloc[0]\n",
    "    # buscar conversion\n",
    "    converted = False\n",
    "    conversion_info = None\n",
    "    # consideramos cualquier visita con is_dementia==1 y vis_month <= 36\n",
    "    dem_vis = subdf[subdf['is_dementia']==1]\n",
    "    if not dem_vis.empty:\n",
    "        # si hay baseline non-dementia, la conversi√≥n debe ocurrir tras baseline\n",
    "        if first_non_d is not None:\n",
    "            # buscar dem_vis cuya month >= baseline month y <=36\n",
    "            base_month = first_non_d.get('vis_month', 0) if pd.notnull(first_non_d.get('vis_month', np.nan)) else 0\n",
    "            # candidate dem_vis posteriores\n",
    "            for _, r in dem_vis.iterrows():\n",
    "                month = r.get('vis_month', np.nan)\n",
    "                if pd.isna(month):\n",
    "                    # si no hay month, intentar por fecha diff\n",
    "                    if pd.notnull(first_non_d['EXAMDATE_parsed']) and pd.notnull(r['EXAMDATE_parsed']):\n",
    "                        diff_months = (r['EXAMDATE_parsed'].year - first_non_d['EXAMDATE_parsed'].year)*12 + (r['EXAMDATE_parsed'].month - first_non_d['EXAMDATE_parsed'].month)\n",
    "                        month = diff_months\n",
    "                # now check range\n",
    "                if pd.notnull(month) and (month >= base_month) and (month <= 36):\n",
    "                    converted = True\n",
    "                    conversion_info = (r['VISCODE'], month, r['EXAMDATE_parsed'])\n",
    "                    break\n",
    "        else:\n",
    "            # No baseline non-dementia conocido: fallback -> if any dem_vis within <=36 -> label may be ambiguous:\n",
    "            # we'll mark converted if there's any dem_vis with vis_month<=36\n",
    "            for _, r in dem_vis.iterrows():\n",
    "                month = r.get('vis_month', np.nan)\n",
    "                if pd.notnull(month) and month <= 36:\n",
    "                    converted = True\n",
    "                    conversion_info = (r['VISCODE'], month, r['EXAMDATE_parsed'])\n",
    "                    break\n",
    "    # Save label for all rows of this subject (we attach label at image-row level later)\n",
    "    labels.append({'sujeto_id': subj, 'label_progresion': int(converted), 'conversion_info': conversion_info})\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "print(\"Labels por sujeto (ejemplo):\")\n",
    "display(labels_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b7c73cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest final con labels guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_labels.csv\n",
      "Resumen labels (por sujeto):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_progresion\n",
       "0    31\n",
       "1    22\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV labels por sujeto guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\labels_por_sujeto.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge back al df (por sujeto_id)\n",
    "df = df.merge(labels_df[['sujeto_id','label_progresion']], on='sujeto_id', how='left')\n",
    "\n",
    "# Guardar manifest con label\n",
    "manifest_final = df[['sujeto_id','id_visita','VISCODE','EXAMDATE','EXAMDATE_parsed','archivo','ruta_abs','ruta_npy','DX','is_dementia','label_progresion']]\n",
    "manifest_final.to_csv(OUT_DIR / \"manifest_labels.csv\", index=False)\n",
    "print(\"Manifest final con labels guardado en:\", OUT_DIR / \"manifest_labels.csv\")\n",
    "\n",
    "# Resumen de labels\n",
    "print(\"Resumen labels (por sujeto):\")\n",
    "display(labels_df['label_progresion'].value_counts(dropna=False))\n",
    "\n",
    "# Guardamos tambi√©n un CSV de sujetos con label para inspecci√≥n\n",
    "labels_df.to_csv(OUT_DIR / \"labels_por_sujeto.csv\", index=False)\n",
    "print(\"CSV labels por sujeto guardado en:\", OUT_DIR / \"labels_por_sujeto.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766f473",
   "metadata": {},
   "source": [
    "## Valores nulos e imputaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786153b",
   "metadata": {},
   "source": [
    "____________\n",
    "* 1. Exploraci√≥n de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ddf68150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de variables nulas \n",
    "cognitivas = [\n",
    "    \"CDRSB\", #\"Suma de cajas del Clinical Dementia Rating (CDR); mide la severidad de la demencia.\",\n",
    "    \"MMSE\", #\"Mini-Mental State Examination; evaluaci√≥n global del estado cognitivo (m√°x. 30 puntos).\",\n",
    "    \"ADAS13\", #\"Alzheimer‚Äôs Disease Assessment Scale ‚Äì 13 √≠tems; mide deterioro cognitivo en Alzheimer.\",\n",
    "    \"FAQ\", #\"Functional Activities Questionnaire; eval√∫a la capacidad funcional en actividades diarias.\",\n",
    "    \"RAVLT_immediate\", # \"Puntuaci√≥n inmediata en la prueba verbal de aprendizaje (Rey Auditory Verbal Learning Test).\",\n",
    "    \"RAVLT_learning\", # \"Puntuaci√≥n de aprendizaje acumulado en RAVLT; mide retenci√≥n verbal.\",\n",
    "    \"RAVLT_forgetting\", # \"√çndice de olvido en RAVLT; diferencia entre aprendizaje y recuerdo tard√≠o.\",\n",
    "    \"DIGITSCOR\", #\"Digit Span Score; mide memoria de trabajo y atenci√≥n mediante secuencias num√©ricas.\",\n",
    "    \"TRABSCOR\", # \"Trail Making Test B Score; eval√∫a funci√≥n ejecutiva y flexibilidad cognitiva.\",\n",
    "]\n",
    "volumen = [\n",
    "    \"Ventricles\", # \"Volumen de los ventr√≠culos cerebrales; puede indicar atrofia cerebral.\",\n",
    "    \"Hippocampus\", # \"Volumen del hipocampo; clave en memoria y afectado en Alzheimer.\",\n",
    "    \"WholeBrain\", # \"Volumen total del cerebro; √∫til para evaluar atrofia global.\",\n",
    "    \"Entorhinal\", # \"Volumen de la corteza entorrinal; regi√≥n afectada tempranamente en Alzheimer.\",\n",
    "    \"Fusiform\", #\"Volumen del giro fusiforme; relacionado con reconocimiento visual.\",\n",
    "    \"MidTemp\", # \"Volumen del l√≥bulo temporal medio; implicado en memoria y procesamiento auditivo.\",\n",
    "    \"ICV\", #\"Volumen intracraneal total; usado para normalizar medidas volum√©tricas.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "10d4132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Valores nulos\n",
      "--------------------------------------------------\n",
      "Variables consideradas (cognitivas): \n",
      "['CDRSB', 'MMSE', 'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR']\n",
      "\n",
      "Resumen de nulos por variable:\n",
      "                  nulos  porcentaje\n",
      "FAQ                  31       10.95\n",
      "ADAS13               29       10.25\n",
      "CDRSB                 0        0.00\n",
      "MMSE                  0        0.00\n",
      "RAVLT_immediate       0        0.00\n",
      "RAVLT_learning        0        0.00\n",
      "RAVLT_forgetting      0        0.00\n",
      "DIGITSCOR             0        0.00\n",
      "TRABSCOR              0        0.00\n",
      "\n",
      "Filas con al menos un nulo en cognitivas: 32\n",
      "Proporci√≥n total: 11.31%\n",
      "--------------------------------------------------\n",
      "Variables consideradas (volumen): \n",
      "['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
      "\n",
      "Resumen de nulos por variable:\n",
      "             nulos  porcentaje\n",
      "Ventricles       0         0.0\n",
      "Hippocampus      0         0.0\n",
      "WholeBrain       0         0.0\n",
      "Entorhinal       0         0.0\n",
      "Fusiform         0         0.0\n",
      "MidTemp          0         0.0\n",
      "ICV              0         0.0\n",
      "\n",
      "Filas con al menos un nulo en volumen: 0\n",
      "Proporci√≥n total: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def resumen_nulos(df, variables, nombre_grupo):\n",
    "    # Asegurar que las variables existan en el DataFrame\n",
    "    variables = [v for v in variables if v in df.columns]\n",
    "    print('-'*50)\n",
    "    print(f\"Variables consideradas ({nombre_grupo}): \\n{variables}\")\n",
    "\n",
    "    # Conteo y proporci√≥n de nulos\n",
    "    nulos_totales = df[variables].isna().sum()\n",
    "    proporcion_nulos = df[variables].isna().mean() * 100\n",
    "\n",
    "    # Mostrar resumen\n",
    "    resumen = pd.DataFrame({\n",
    "        \"nulos\": nulos_totales,\n",
    "        \"porcentaje\": proporcion_nulos.round(2)\n",
    "    }).sort_values(\"porcentaje\", ascending=False)\n",
    "\n",
    "    print(\"\\nResumen de nulos por variable:\")\n",
    "    print(resumen)\n",
    "\n",
    "    # Filas con al menos un nulo en ese grupo\n",
    "    df[f\"nulos_{nombre_grupo}\"] = df[variables].isna().any(axis=1)\n",
    "    total_filas_nulas = df[f\"nulos_{nombre_grupo}\"].sum()\n",
    "    porcentaje_filas_nulas = df[f\"nulos_{nombre_grupo}\"].mean() * 100\n",
    "\n",
    "    print(f\"\\nFilas con al menos un nulo en {nombre_grupo}: {total_filas_nulas}\")\n",
    "    print(f\"Proporci√≥n total: {porcentaje_filas_nulas:.2f}%\")\n",
    "\n",
    "print('-'*50)\n",
    "print('Valores nulos')\n",
    "resumen_nulos(df, cognitivas, \"cognitivas\")\n",
    "resumen_nulos(df, volumen, \"volumen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "723f4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputaci√≥n\n",
      "--------------------------------------------------\n",
      "Variables num√©ricas para imputaci√≥n (cognitivas):\n",
      "['CDRSB', 'MMSE', 'ADAS13', 'FAQ', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'DIGITSCOR', 'TRABSCOR']\n",
      "‚úÖ Imputaci√≥n completada.\n",
      "\n",
      "üìÅ Archivo guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_cognitivas_imputadas.csv\n",
      "--------------------------------------------------\n",
      "Variables num√©ricas para imputaci√≥n (volumen):\n",
      "['Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
      "‚úÖ Imputaci√≥n completada.\n",
      "\n",
      "üìÅ Archivo guardado en: C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\\manifest_volumen_imputadas.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def imputar_y_normalizar(df, variables, nombre_grupo, out_dir=None):\n",
    "   \n",
    "    print('-'*50)\n",
    "    # Filtrar solo variables num√©ricas v√°lidas\n",
    "    variables_num = [v for v in variables if v in df.columns and df[v].dtype.kind in \"iufc\"]\n",
    "    print(f\"Variables num√©ricas para imputaci√≥n ({nombre_grupo}):\\n{variables_num}\")\n",
    "\n",
    "    # Subset de datos\n",
    "    datos = df[variables_num].copy()\n",
    "\n",
    "    # Imputaci√≥n multivariada\n",
    "    # Modelo bayesiano iterativo para predecir valores faltantes en funci√≥n de las dem√°s variables.\n",
    "    imputer = IterativeImputer(random_state=42, max_iter=20, sample_posterior=True)\n",
    "    datos_imputados = imputer.fit_transform(datos)\n",
    "\n",
    "    # Convertir a DataFrame imputado\n",
    "    df_imputado = pd.DataFrame(datos_imputados, columns=variables_num, index=df.index)\n",
    "\n",
    "    # Reemplazar en el DataFrame original\n",
    "    for v in variables_num:\n",
    "        df[v] = df_imputado[v]\n",
    "\n",
    "    print(\"‚úÖ Imputaci√≥n completada.\")\n",
    "\n",
    "    # Normalizaci√≥n z-score\n",
    "    scaler = StandardScaler()\n",
    "    df_std = pd.DataFrame(\n",
    "        scaler.fit_transform(df[variables_num]),\n",
    "        columns=[v + \"_std\" for v in variables_num],\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    # Concatenar al DataFrame original\n",
    "    df = pd.concat([df, df_std], axis=1)\n",
    "\n",
    "    # Guardar salida si se especifica ruta\n",
    "    if out_dir:\n",
    "        nombre_archivo = f\"manifest_{nombre_grupo}_imputadas.csv\"\n",
    "        ruta_out = out_dir / nombre_archivo\n",
    "        df.to_csv(ruta_out, index=False)\n",
    "        print(f\"\\nüìÅ Archivo guardado en: {ruta_out}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "print('Imputaci√≥n')\n",
    "df = imputar_y_normalizar(df, cognitivas, \"cognitivas\", OUT_DIR)\n",
    "df = imputar_y_normalizar(df, volumen, \"volumen\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a283c6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "üìÅ Valores nulos:\n",
      "Variables con valores nulos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Cantidad_nulos</th>\n",
       "      <th>Porcentaje_nulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DX</td>\n",
       "      <td>28</td>\n",
       "      <td>9.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_dementia</td>\n",
       "      <td>28</td>\n",
       "      <td>9.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable  Cantidad_nulos  Porcentaje_nulos\n",
       "0           DX              28              9.89\n",
       "1  is_dementia              28              9.89"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"-\" * 30)\n",
    "print(\"üìÅ Valores nulos:\")\n",
    "print(f\"Variables con valores nulos:\")\n",
    "nulos = df.isna().sum()\n",
    "porcentaje = (nulos / len(df)) * 100\n",
    "tabla_nulos = pd.DataFrame({\n",
    "    \"Variable\": nulos.index,\n",
    "    \"Cantidad_nulos\": nulos.values,\n",
    "    \"Porcentaje_nulos\": porcentaje.round(2)\n",
    "})\n",
    "tabla_nulos = tabla_nulos[tabla_nulos[\"Cantidad_nulos\"] > 0]\n",
    "tabla_nulos = tabla_nulos.sort_values(by=\"Cantidad_nulos\", ascending=False).reset_index(drop=True)\n",
    "tabla_nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0c0808e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sujeto_id',\n",
       " 'shape',\n",
       " 'voxel_size',\n",
       " 'datatype',\n",
       " 'voxel_volume_mm3',\n",
       " 'total_volume',\n",
       " 'mean_intensity',\n",
       " 'std_intensity',\n",
       " 'orientation',\n",
       " 'units',\n",
       " 'archivo',\n",
       " 'ruta',\n",
       " 'VISCODE',\n",
       " 'EXAMDATE',\n",
       " 'DX',\n",
       " 'AGE',\n",
       " 'PTGENDER',\n",
       " 'PTEDUCAT',\n",
       " 'APOE4',\n",
       " 'CDRSB',\n",
       " 'MMSE',\n",
       " 'ADAS13',\n",
       " 'FAQ',\n",
       " 'RAVLT_immediate',\n",
       " 'RAVLT_learning',\n",
       " 'RAVLT_forgetting',\n",
       " 'DIGITSCOR',\n",
       " 'TRABSCOR',\n",
       " 'Ventricles',\n",
       " 'Hippocampus',\n",
       " 'WholeBrain',\n",
       " 'Entorhinal',\n",
       " 'Fusiform',\n",
       " 'MidTemp',\n",
       " 'ICV',\n",
       " 'ruta_abs',\n",
       " 'EXAMDATE_parsed',\n",
       " 'id_visita',\n",
       " 'fname_out',\n",
       " 'ruta_npy',\n",
       " 'vis_month',\n",
       " 'is_dementia',\n",
       " 'label_progresion',\n",
       " 'nulos_cognitivas',\n",
       " 'nulos_volumen',\n",
       " 'CDRSB_std',\n",
       " 'MMSE_std',\n",
       " 'RAVLT_immediate_std',\n",
       " 'RAVLT_learning_std',\n",
       " 'RAVLT_forgetting_std',\n",
       " 'DIGITSCOR_std',\n",
       " 'TRABSCOR_std',\n",
       " 'Ventricles_std',\n",
       " 'Hippocampus_std',\n",
       " 'WholeBrain_std',\n",
       " 'Entorhinal_std',\n",
       " 'Fusiform_std',\n",
       " 'MidTemp_std',\n",
       " 'ICV_std']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACHINE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
