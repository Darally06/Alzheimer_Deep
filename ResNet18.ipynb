{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9ff18c",
   "metadata": {},
   "source": [
    "# **ResNet18 como modelo base**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b49aa1",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355b2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import os, glob, math, random, time, json, torch_directml\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print('PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbb90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "DATA_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\")\n",
    "LABELS_CSV = r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\\Data\\atributos.csv\"\n",
    "OUTPUT_DIR = \"models_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfc143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: intensity normalization, slice extraction\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def contrast_normalize_volume(vol, pmin=2, pmax=98):     \n",
    "    vmin = np.percentile(vol, pmin)    \n",
    "    vmax = np.percentile(vol, pmax)    \n",
    "    vol = np.clip(vol, vmin, vmax)    \n",
    "    vol = (vol - vmin) / (vmax - vmin + 1e-9)    \n",
    "    return vol.astype(np.float32)\n",
    "\n",
    "def get_central_slices(vol, n_slices=10):  \n",
    "    \"\"\" Extract n central axial slices from a volume shaped.   \"\"\"\n",
    "    D = vol.shape[0]    \n",
    "    center = D // 2    \n",
    "    half = n_slices // 2   \n",
    "    start = max(0, center - half)    \n",
    "    end = min(D, start + n_slices)\n",
    "    slices = vol[start:end]\n",
    "    if slices.shape[0] < n_slices:  # padding si faltan\n",
    "        pad_before = (n_slices - slices.shape[0]) // 2\n",
    "        pad_after = n_slices - slices.shape[0] - pad_before\n",
    "        slices = np.concatenate([\n",
    "            np.repeat(slices[[0]], pad_before, axis=0),\n",
    "            slices,\n",
    "            np.repeat(slices[[-1]], pad_after, axis=0)\n",
    "        ], axis=0)\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0a342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: loads one volume per item and returns tensor of shape (n_slices, C, H, W)\n",
    "class MRIVolumeDataset(Dataset):\n",
    "    def __init__(self, records, n_slices=10, target_size=(224,224), transform=None, skull_strip=False):\n",
    "        self.records = records        \n",
    "        self.n_slices = n_slices        \n",
    "        self.target_size = target_size        \n",
    "        self.transform = transform        \n",
    "        self.skull_strip = skull_strip    \n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.records)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        vol = np.load(rec['path'])  # Volumen (160,192,192)\n",
    "\n",
    "        vol = contrast_normalize_volume(vol)\n",
    "        slices = get_central_slices(vol, self.n_slices)\n",
    "\n",
    "        imgs = []\n",
    "        for s in slices:\n",
    "            img = Image.fromarray((s * 255).astype(np.uint8))\n",
    "            img = img.resize(self.target_size)\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                img = T.Compose([\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                ])(img)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = torch.stack(imgs, dim=0)  # (n_slices, C, H, W)\n",
    "        label = torch.tensor(rec['label'], dtype=torch.float32)\n",
    "        \n",
    "        return imgs, label, rec['sujeto_id']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d358e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Clase] Modelo RestNet\n",
    "class ResNetSliceClassifier(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet18', pretrained=False, n_slices=10, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.n_slices = n_slices\n",
    "\n",
    "        if backbone_name == 'resnet18':\n",
    "            base = resnet18(weights=None if not pretrained else ResNet18_Weights.DEFAULT)\n",
    "            feat_dim = base.fc.in_features\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo no soportado: {backbone_name}\")\n",
    "        # Secuencia de la red\n",
    "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(feat_dim, 1)\n",
    "\n",
    "    # Paso forward\n",
    "    def forward(self, x):\n",
    "        B, S, C, H, W = x.shape\n",
    "        x = x.view(B*S, C, H, W)\n",
    "        feats = self.backbone(x)\n",
    "        feats = self.global_pool(feats).view(B, S, -1)\n",
    "        agg = feats.mean(dim=1)\n",
    "        out = self.dropout(agg)\n",
    "        logits = self.classifier(out).squeeze(1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4773d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_records(data_dir, labels_csv):\n",
    "    labels_df = pd.read_csv(labels_csv, dtype={'sujeto_id': str})\n",
    "    labels_df = labels_df.dropna(subset=['is_dementia']) # Excluir imÃ¡genes sin datos\n",
    "    labels_df['sujeto_id'] = labels_df['sujeto_id'].str.strip()\n",
    "    label_map = dict(zip(labels_df['sujeto_id'], labels_df['is_dementia']))\n",
    "\n",
    "    records = []\n",
    "    for p in glob.glob(os.path.join(data_dir, \"*.npy\")):\n",
    "        subj = os.path.basename(p)[:10].strip()\n",
    "        if subj in label_map:\n",
    "            records.append({\"path\": p, \"sujeto_id\": subj, \"label\": int(label_map[subj])})\n",
    "    return records\n",
    "\n",
    "# DivisiÃ³n estratificada\n",
    "def group_stratified_split(records, train_size=0.7, val_size=0.15, test_size=0.15, seed=42):\n",
    "    df = pd.DataFrame(records)\n",
    "    subj_lab = df.groupby(\"sujeto_id\")[\"label\"].agg(lambda x: int(round(x.mean())))\n",
    "    subjects = subj_lab.index.to_list()\n",
    "    y = subj_lab.values\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=seed)\n",
    "    train_idx, rest_idx = next(gss.split(subjects, y, groups=subjects))\n",
    "    train_subj = [subjects[i] for i in train_idx]\n",
    "    rest_subj = [subjects[i] for i in rest_idx]\n",
    "\n",
    "    val_prop = val_size / (val_size + test_size)\n",
    "    val_subj, test_subj = train_test_split(rest_subj, test_size=1 - val_prop, random_state=seed, stratify=[subj_lab[s] for s in rest_subj])\n",
    "\n",
    "    def select_by_subject(subj_list):\n",
    "        return [r for r in records if r[\"sujeto_id\"] in subj_list]\n",
    "\n",
    "    return select_by_subject(train_subj), select_by_subject(val_subj), select_by_subject(test_subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d5e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(records):\n",
    "    labels = [r['label'] for r in records]\n",
    "    cnt0 = sum(l == 0 for l in labels)\n",
    "    cnt1 = sum(l == 1 for l in labels)\n",
    "    pos_weight = torch.tensor([cnt0 / (cnt1 + 1e-9)], dtype=torch.float32)\n",
    "    return pos_weight, cnt0, cnt1\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    ys, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y, _ in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            probs = torch.sigmoid(model(X)).cpu().numpy()\n",
    "            preds.extend((probs >= 0.5).astype(int))\n",
    "            ys.extend(y.cpu().numpy().astype(int))\n",
    "    return balanced_accuracy_score(ys, preds)\n",
    "\n",
    "# Entrenamiento por Ã©pocas\n",
    "def train_one_model(model, train_loader, val_loader, device, pos_weight, lr=1e-4, epochs=10, patience=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    best_bac = 0\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"val_bac\": []}\n",
    "    time_1 = time.time()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        val_bac = evaluate_model(model, val_loader, device)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {e+1}/{epochs} | Loss {total_loss/len(train_loader):.4f} | Val BAC {val_bac:.4f} | Tiempo {epoch_time/60:.2f} minutos\")\n",
    "        \n",
    "        # Guardar historia\n",
    "        history[\"epoch\"].append(e + 1)\n",
    "        history[\"train_loss\"].append(avg_loss)\n",
    "        history[\"val_bac\"].append(val_bac)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_bac > best_bac:\n",
    "            best_bac = val_bac\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping activado en epoch {e+1}\")\n",
    "                break\n",
    "\n",
    "    total_time = time.time() - time_1\n",
    "    print(f\"Entrenamiento completo en {total_time/60:.2f} minutos\")\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5722d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar rendimiento\n",
    "def plot_training_history(history, model_name=\"modelo\"):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "    plt.plot(history[\"epoch\"], history[\"val_bac\"], label=\"Val Balanced Accuracy\", marker=\"s\")\n",
    "    plt.xlabel(\"Ã‰poca\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.title(f\"EvoluciÃ³n del entrenamiento - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar imagen\n",
    "    filename = f\"models_output/history_{model_name}.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"GrÃ¡fico guardado en: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6a11a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dry_run=True):\n",
    "    records = build_records(DATA_DIR, LABELS_CSV)\n",
    "    print(f\"VolÃºmenes encontrados: {len(records)}\")\n",
    "    train_recs, val_recs, test_recs = group_stratified_split(records, seed = SEED)\n",
    "    pos_weight, c0, c1 = compute_class_weights(train_recs)\n",
    "    print(f\"Clases: 0={c0}, 1={c1}, pos_weight={pos_weight.item():.2f}\")\n",
    "    print(f\"Bach {BATCH_SIZE}, slices {N_SLICES}, epocas {EPOCHS}, patience {PATIENCE}\")\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.RandomHorizontalFlip(0.5),\n",
    "        T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    # Extraer imÃ¡genes\n",
    "    train_ds = MRIVolumeDataset(train_recs, transform=transform)\n",
    "    val_ds = MRIVolumeDataset(val_recs)\n",
    "    test_ds = MRIVolumeDataset(test_recs)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    if dry_run:\n",
    "        X, y, _ = next(iter(train_loader))\n",
    "        print(\"Ejemplo:\", X.shape, y.shape)\n",
    "        return\n",
    "\n",
    "    # Estructura principal\n",
    "    results = []\n",
    "    for backbone in ['resnet18']:\n",
    "        print(f\"\\n=== Entrenando {backbone} ===\")\n",
    "        model = ResNetSliceClassifier(backbone, n_slices=N_SLICES) # type: ignore\n",
    "        trained, history = train_one_model(model, train_loader, val_loader, DEVICE, pos_weight, lr=LR, epochs=EPOCHS, patience=PATIENCE)\n",
    "        test_bac = evaluate_model(trained, test_loader, DEVICE)\n",
    "        results.append((backbone, test_bac))\n",
    "        print(f\"Test BAC ({backbone}): {test_bac:.4f}\")\n",
    "\n",
    "        torch.save(trained.state_dict(), f\"{OUTPUT_DIR}/{backbone}_filter_Slices{N_SLICES}_Learning{LR}_model.pth\")\n",
    "        print(f\"Modelo guardado: {OUTPUT_DIR}/{backbone}_filter_Slices{N_SLICES}_Learning{LR}_model.pth\")\n",
    "\n",
    "        plot_training_history(history, model_name=f\"{backbone}_slices{N_SLICES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacb7b4",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a008b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device -> cpu\n"
     ]
    }
   ],
   "source": [
    "# [config] HiperparÃ¡metros fijos\n",
    "TARGET_SIZE = (224,224)\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "print('Device ->', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": null,
>>>>>>> 396926bc3254aa44d8873e5dffcd03079099ff73
   "id": "fcbe1c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VolÃºmenes encontrados: 279\n",
      "Clases: 0=74, 1=116, pos_weight=0.64\n",
      "Bach 8, slices 20, epocas 20, patience 5\n",
      "\n",
<<<<<<< HEAD
      "=== Entrenando resnet18 ===\n",
      "Epoch 3/20 | Loss 0.5035 | Val BAC 0.3198 | Tiempo 3.35 minutos\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n\u001b[0;32m      6\u001b[0m PATIENCE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(dry_run)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Entrenando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNetSliceClassifier(backbone, n_slices\u001b[38;5;241m=\u001b[39mN_SLICES) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m trained, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATIENCE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m test_bac \u001b[38;5;241m=\u001b[39m evaluate_model(trained, test_loader, DEVICE)\n\u001b[0;32m     37\u001b[0m results\u001b[38;5;241m.\u001b[39mappend((backbone, test_bac))\n",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m, in \u001b[0;36mtrain_one_model\u001b[1;34m(model, train_loader, val_loader, device, pos_weight, lr, epochs, patience)\u001b[0m\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     36\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y, _ \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     38\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     39\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mMRIVolumeDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecords[idx]\n\u001b[0;32m     15\u001b[0m vol \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(rec[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Volumen (160,192,192)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m vol \u001b[38;5;241m=\u001b[39m \u001b[43mcontrast_normalize_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m slices \u001b[38;5;241m=\u001b[39m get_central_slices(vol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_slices)\n\u001b[0;32m     20\u001b[0m imgs \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m, in \u001b[0;36mcontrast_normalize_volume\u001b[1;34m(vol, pmin, pmax)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrast_normalize_volume\u001b[39m(vol, pmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, pmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m98\u001b[39m):     \n\u001b[0;32m     11\u001b[0m     vmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(vol, pmin)    \n\u001b[1;32m---> 12\u001b[0m     vmax \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpercentile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmax\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     13\u001b[0m     vol \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(vol, vmin, vmax)    \n\u001b[0;32m     14\u001b[0m     vol \u001b[38;5;241m=\u001b[39m (vol \u001b[38;5;241m-\u001b[39m vmin) \u001b[38;5;241m/\u001b[39m (vmax \u001b[38;5;241m-\u001b[39m vmin \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-9\u001b[39m)    \n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4273\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, weights, interpolation)\u001b[0m\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(weights \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   4271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights must be non-negative.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4274\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4550\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, weights)\u001b[0m\n\u001b[0;32m   4541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4542\u001b[0m                         q,\n\u001b[0;32m   4543\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4547\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   4548\u001b[0m                         weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4551\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4552\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4553\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4554\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4555\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4556\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4557\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4558\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3894\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3891\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   3892\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[1;32m-> 3894\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Hp\\anaconda3\\envs\\MACHINE\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4722\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, weights, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4721\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 4722\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4723\u001b[0m     wgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m   4724\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
=======
      "=== Entrenando resnet18 ===\n"
>>>>>>> 396926bc3254aa44d8873e5dffcd03079099ff73
     ]
    }
   ],
   "source": [
    "# 1. HiperparÃ¡metros variables\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 20         # Ã‰pocas para entrenar\n",
    "N_SLICES = 20\n",
    "LR = 1e-5\n",
    "PATIENCE = 5\n",
    "main(dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26745170",
   "metadata": {},
   "source": [
    "| Variante                                 |                 LR (init / schedule) | Weight decay | Ã‰pocas | Slices | Patience | Loss / balance                           |              Batch | ObservaciÃ³n / objetivo                                                                                                   | Prioridad |\n",
    "| ---------------------------------------- | -----------------------------------: | -----------: | -----: | -----: | -------: | ---------------------------------------- | -----------------: | ------------------------------------------------------------------------------------------------------------------------ | --------: |\n",
    "| **Base (control)**                       |                             **1e-5** |     **1e-5** |     20 |     20 |        5 | BCEWithLogits + pos_weight=0.64          |                  8 | Punto de partida (tu mejor hasta ahora). Verificar reproducibilidad.                                                     |   ðŸ”· Alta |\n",
    "| **V1 â€” LR subida leve**                  |                                 3e-5 |         1e-5 |     20 |     20 |        5 | BCEWithLogits + pos_weight               |                  8 | LR un poco mayor para acelerar convergencia sin desestabilizar. Good first test.                                         |   ðŸ”· Alta |\n",
    "| **V2 â€” LR mÃ¡s alto (exploratorio)**      |                                 1e-4 |         1e-5 |     20 |     20 |        5 | BCEWithLogits + pos_weight               |                  8 | Prueba el LR que preguntaste; detecta si entrenar mÃ¡s rÃ¡pido ayuda o provoca inestabilidad.                              |  ðŸ”¶ Media |\n",
    "| **V3 â€” MÃ¡s regularizaciÃ³n + mÃ¡s Ã©pocas** |                                 1e-5 |     **1e-4** | **30** |     20 |        5 | BCEWithLogits + pos_weight (o Focal Î³=2) |                  8 | Aumentar WD para combatir overfitting al extender entrenamiento; probar Focal si hay ejemplos difÃ­ciles.                 |   ðŸ”· Alta |\n",
    "| **V4 â€” MÃ¡s contexto espacial**           |                                 1e-5 |         1e-5 |     30 | **30** |        5 | BCEWithLogits + pos_weight               | 8 (o 4 si memoria) | Aumentar slices a 30 (si lo soporta GPU) para mejorar seÃ±ales 3D; mÃ¡s Ã©pocas para aprovecharlo.                          |  ðŸ”¶ Media |\n",
    "| **V5 â€” Scheduler / OneCycle**            | base_lr=1e-5, max_lr=1e-4 (OneCycle) |         1e-5 |     30 |     20 |        5 | BCEWithLogits + pos_weight (o Focal)     |                  8 | Uso de OneCycle (o cosine) para combinar estabilidad inicial y picos de LR: suele dar buen rendimiento sin mucha tuning. |   ðŸ”· Alta |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACHINE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
