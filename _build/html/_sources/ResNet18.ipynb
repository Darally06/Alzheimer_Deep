{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9ff18c",
   "metadata": {},
   "source": [
    "# **ResNet18 como modelo base**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b49aa1",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355b2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import os, glob, math, random, time, json, torch_directml\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print('PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbb90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "DATA_DIR = Path(r\"C:\\Users\\Hp\\MACHINE\\MRI\\datos\\procesadas\")\n",
    "LABELS_CSV = r\"C:\\Users\\Hp\\MACHINE\\MRI\\notebooks\\Data\\atributos.csv\"\n",
    "OUTPUT_DIR = \"models_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfc143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: intensity normalization, slice extraction\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def contrast_normalize_volume(vol, pmin=2, pmax=98):     \n",
    "    vmin = np.percentile(vol, pmin)    \n",
    "    vmax = np.percentile(vol, pmax)    \n",
    "    vol = np.clip(vol, vmin, vmax)    \n",
    "    vol = (vol - vmin) / (vmax - vmin + 1e-9)    \n",
    "    return vol.astype(np.float32)\n",
    "\n",
    "def get_central_slices(vol, n_slices=10):  \n",
    "    \"\"\" Extract n central axial slices from a volume shaped.   \"\"\"\n",
    "    D = vol.shape[0]    \n",
    "    center = D // 2    \n",
    "    half = n_slices // 2   \n",
    "    start = max(0, center - half)    \n",
    "    end = min(D, start + n_slices)\n",
    "    slices = vol[start:end]\n",
    "    if slices.shape[0] < n_slices:  # padding si faltan\n",
    "        pad_before = (n_slices - slices.shape[0]) // 2\n",
    "        pad_after = n_slices - slices.shape[0] - pad_before\n",
    "        slices = np.concatenate([\n",
    "            np.repeat(slices[[0]], pad_before, axis=0),\n",
    "            slices,\n",
    "            np.repeat(slices[[-1]], pad_after, axis=0)\n",
    "        ], axis=0)\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0a342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: loads one volume per item and returns tensor of shape (n_slices, C, H, W)\n",
    "class MRIVolumeDataset(Dataset):\n",
    "    def __init__(self, records, n_slices=10, target_size=(224,224), transform=None, skull_strip=False):\n",
    "        self.records = records        \n",
    "        self.n_slices = n_slices        \n",
    "        self.target_size = target_size        \n",
    "        self.transform = transform        \n",
    "        self.skull_strip = skull_strip    \n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.records)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        vol = np.load(rec['path'])  # Volumen (160,192,192)\n",
    "\n",
    "        vol = contrast_normalize_volume(vol)\n",
    "        slices = get_central_slices(vol, self.n_slices)\n",
    "\n",
    "        imgs = []\n",
    "        for s in slices:\n",
    "            img = Image.fromarray((s * 255).astype(np.uint8))\n",
    "            img = img.resize(self.target_size)\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                img = T.Compose([\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                ])(img)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = torch.stack(imgs, dim=0)  # (n_slices, C, H, W)\n",
    "        label = torch.tensor(rec['label'], dtype=torch.float32)\n",
    "        \n",
    "        return imgs, label, rec['sujeto_id']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d358e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Clase] Modelo RestNet\n",
    "class ResNetSliceClassifier(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet18', pretrained=False, n_slices=10, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.n_slices = n_slices\n",
    "\n",
    "        if backbone_name == 'resnet18':\n",
    "            base = resnet18(weights=None if not pretrained else ResNet18_Weights.DEFAULT)\n",
    "            feat_dim = base.fc.in_features\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo no soportado: {backbone_name}\")\n",
    "        # Secuencia de la red\n",
    "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(feat_dim, 1)\n",
    "\n",
    "    # Paso forward\n",
    "    def forward(self, x):\n",
    "        B, S, C, H, W = x.shape\n",
    "        x = x.view(B*S, C, H, W)\n",
    "        feats = self.backbone(x)\n",
    "        feats = self.global_pool(feats).view(B, S, -1)\n",
    "        agg = feats.mean(dim=1)\n",
    "        out = self.dropout(agg)\n",
    "        logits = self.classifier(out).squeeze(1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4773d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_records(data_dir, labels_csv):\n",
    "    labels_df = pd.read_csv(labels_csv, dtype={'sujeto_id': str})\n",
    "    labels_df = labels_df.dropna(subset=['is_dementia']) # Excluir imágenes sin datos\n",
    "    labels_df['sujeto_id'] = labels_df['sujeto_id'].str.strip()\n",
    "    label_map = dict(zip(labels_df['sujeto_id'], labels_df['is_dementia']))\n",
    "\n",
    "    records = []\n",
    "    for p in glob.glob(os.path.join(data_dir, \"*.npy\")):\n",
    "        subj = os.path.basename(p)[:10].strip()\n",
    "        if subj in label_map:\n",
    "            records.append({\"path\": p, \"sujeto_id\": subj, \"label\": int(label_map[subj])})\n",
    "    return records\n",
    "\n",
    "# División estratificada\n",
    "def group_stratified_split(records, train_size=0.7, val_size=0.15, test_size=0.15, seed=42):\n",
    "    df = pd.DataFrame(records)\n",
    "    subj_lab = df.groupby(\"sujeto_id\")[\"label\"].agg(lambda x: int(round(x.mean())))\n",
    "    subjects = subj_lab.index.to_list()\n",
    "    y = subj_lab.values\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=seed)\n",
    "    train_idx, rest_idx = next(gss.split(subjects, y, groups=subjects))\n",
    "    train_subj = [subjects[i] for i in train_idx]\n",
    "    rest_subj = [subjects[i] for i in rest_idx]\n",
    "\n",
    "    val_prop = val_size / (val_size + test_size)\n",
    "    val_subj, test_subj = train_test_split(rest_subj, test_size=1 - val_prop, random_state=seed, stratify=[subj_lab[s] for s in rest_subj])\n",
    "\n",
    "    def select_by_subject(subj_list):\n",
    "        return [r for r in records if r[\"sujeto_id\"] in subj_list]\n",
    "\n",
    "    return select_by_subject(train_subj), select_by_subject(val_subj), select_by_subject(test_subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d5e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(records):\n",
    "    labels = [r['label'] for r in records]\n",
    "    cnt0 = sum(l == 0 for l in labels)\n",
    "    cnt1 = sum(l == 1 for l in labels)\n",
    "    pos_weight = torch.tensor([cnt0 / (cnt1 + 1e-9)], dtype=torch.float32)\n",
    "    return pos_weight, cnt0, cnt1\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    ys, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y, _ in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            probs = torch.sigmoid(model(X)).cpu().numpy()\n",
    "            preds.extend((probs >= 0.5).astype(int))\n",
    "            ys.extend(y.cpu().numpy().astype(int))\n",
    "    return balanced_accuracy_score(ys, preds)\n",
    "\n",
    "# Entrenamiento por épocas\n",
    "def train_one_model(model, train_loader, val_loader, device, pos_weight, lr=1e-4, epochs=10, patience=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    best_bac = 0\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"val_bac\": []}\n",
    "    time_1 = time.time()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        val_bac = evaluate_model(model, val_loader, device)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {e+1}/{epochs} | Loss {total_loss/len(train_loader):.4f} | Val BAC {val_bac:.4f} | Tiempo {epoch_time/60:.2f} minutos\")\n",
    "        \n",
    "        # Guardar historia\n",
    "        history[\"epoch\"].append(e + 1)\n",
    "        history[\"train_loss\"].append(avg_loss)\n",
    "        history[\"val_bac\"].append(val_bac)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_bac > best_bac:\n",
    "            best_bac = val_bac\n",
    "            best_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping activado en epoch {e+1}\")\n",
    "                break\n",
    "\n",
    "    total_time = time.time() - time_1\n",
    "    print(f\"Entrenamiento completo en {total_time/60:.2f} minutos\")\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5722d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar rendimiento\n",
    "def plot_training_history(history, model_name=\"modelo\"):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "    plt.plot(history[\"epoch\"], history[\"val_bac\"], label=\"Val Balanced Accuracy\", marker=\"s\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.title(f\"Evolución del entrenamiento - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar imagen\n",
    "    filename = f\"models_output/history_{model_name}.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Gráfico guardado en: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a11a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dry_run=True):\n",
    "    records = build_records(DATA_DIR, LABELS_CSV)\n",
    "    print(f\"Volúmenes encontrados: {len(records)}\")\n",
    "    train_recs, val_recs, test_recs = group_stratified_split(records, seed = SEED)\n",
    "    pos_weight, c0, c1 = compute_class_weights(train_recs)\n",
    "    print(f\"Clases: 0={c0}, 1={c1}, pos_weight={pos_weight.item():.2f}\")\n",
    "    print(f\"Bach {BATCH_SIZE}, slices {N_SLICES}, epocas {EPOCHS}, patience {PATIENCE}\")\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.RandomHorizontalFlip(0.5),\n",
    "        T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    # Extraer imágenes\n",
    "    train_ds = MRIVolumeDataset(train_recs, transform=transform)\n",
    "    val_ds = MRIVolumeDataset(val_recs)\n",
    "    test_ds = MRIVolumeDataset(test_recs)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    if dry_run:\n",
    "        X, y, _ = next(iter(train_loader))\n",
    "        print(\"Ejemplo:\", X.shape, y.shape)\n",
    "        return\n",
    "\n",
    "    # Estructura principal\n",
    "    results = []\n",
    "    for backbone in ['resnet18']:\n",
    "        print(f\"\\n=== Entrenando {backbone} ===\")\n",
    "        model = ResNetSliceClassifier(backbone, n_slices=N_SLICES) # type: ignore\n",
    "        trained, history = train_one_model(model, train_loader, val_loader, DEVICE, pos_weight, lr=LR, epochs=EPOCHS, patience=PATIENCE)\n",
    "        test_bac = evaluate_model(trained, test_loader, DEVICE)\n",
    "        results.append((backbone, test_bac))\n",
    "        print(f\"Test BAC ({backbone}): {test_bac:.4f}\")\n",
    "\n",
    "        torch.save(trained.state_dict(), f\"{OUTPUT_DIR}/{backbone}_filter_Slices{N_SLICES}_Learning{LR}_model.pth\")\n",
    "        print(f\"Modelo guardado: {OUTPUT_DIR}/{backbone}_filter_Slices{N_SLICES}_Learning{LR}_model.pth\")\n",
    "\n",
    "        plot_training_history(history, model_name=f\"{backbone}_slices{N_SLICES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacb7b4",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a008b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device -> cpu\n"
     ]
    }
   ],
   "source": [
    "# [config] Hiperparámetros fijos\n",
    "TARGET_SIZE = (224,224)\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "print('Device ->', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe1c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volúmenes encontrados: 279\n",
      "Clases: 0=74, 1=116, pos_weight=0.64\n",
      "Bach 8, slices 20, epocas 20, patience 5\n",
      "\n",
      "=== Entrenando resnet18 ===\n"
     ]
    }
   ],
   "source": [
    "# 1. Hiperparámetros variables\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 20         # Épocas para entrenar\n",
    "N_SLICES = 20\n",
    "LR = 1e-5\n",
    "PATIENCE = 5\n",
    "main(dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26745170",
   "metadata": {},
   "source": [
    "| Variante                                 |                 LR (init / schedule) | Weight decay | Épocas | Slices | Patience | Loss / balance                           |              Batch | Observación / objetivo                                                                                                   | Prioridad |\n",
    "| ---------------------------------------- | -----------------------------------: | -----------: | -----: | -----: | -------: | ---------------------------------------- | -----------------: | ------------------------------------------------------------------------------------------------------------------------ | --------: |\n",
    "| **Base (control)**                       |                             **1e-5** |     **1e-5** |     20 |     20 |        5 | BCEWithLogits + pos_weight=0.64          |                  8 | Punto de partida (tu mejor hasta ahora). Verificar reproducibilidad.                                                     |   🔷 Alta |\n",
    "| **V1 — LR subida leve**                  |                                 3e-5 |         1e-5 |     20 |     20 |        5 | BCEWithLogits + pos_weight               |                  8 | LR un poco mayor para acelerar convergencia sin desestabilizar. Good first test.                                         |   🔷 Alta |\n",
    "| **V2 — LR más alto (exploratorio)**      |                                 1e-4 |         1e-5 |     20 |     20 |        5 | BCEWithLogits + pos_weight               |                  8 | Prueba el LR que preguntaste; detecta si entrenar más rápido ayuda o provoca inestabilidad.                              |  🔶 Media |\n",
    "| **V3 — Más regularización + más épocas** |                                 1e-5 |     **1e-4** | **30** |     20 |        5 | BCEWithLogits + pos_weight (o Focal γ=2) |                  8 | Aumentar WD para combatir overfitting al extender entrenamiento; probar Focal si hay ejemplos difíciles.                 |   🔷 Alta |\n",
    "| **V4 — Más contexto espacial**           |                                 1e-5 |         1e-5 |     30 | **30** |        5 | BCEWithLogits + pos_weight               | 8 (o 4 si memoria) | Aumentar slices a 30 (si lo soporta GPU) para mejorar señales 3D; más épocas para aprovecharlo.                          |  🔶 Media |\n",
    "| **V5 — Scheduler / OneCycle**            | base_lr=1e-5, max_lr=1e-4 (OneCycle) |         1e-5 |     30 |     20 |        5 | BCEWithLogits + pos_weight (o Focal)     |                  8 | Uso de OneCycle (o cosine) para combinar estabilidad inicial y picos de LR: suele dar buen rendimiento sin mucha tuning. |   🔷 Alta |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACHINE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
